% ============================================
% CHAPTER: SHAP VALUES FOR MODEL 9 INTERPRETABILITY
% ============================================

\chapter{SHAP Values: Mathematical Foundation for Model 9 (Random Forest) Interpretability}\label{ch:shap_values}


% ============================================
\section{Introduction}
% ============================================
Model 9 implements a static Random Forest configuration with \ModelNineNTrees{} decision trees (150 in the implementation) and no target transformation or hyperparameter tuning.\footnote{See Model 9 code for fixed parameters: $n\_estimators=150$, $max\_depth=15$, $min\_samples\_split=8$, $min\_samples\_leaf=3$, $max\_features=\sqrt{\cdot}$, $bootstrap{=}$True, $oob\_score{=}$True, $random\_state{=}42$.} While the ensemble's predictions emerge from aggregating multiple tree decisions, individual allocation explanations require additional interpretation methods. SHAP (SHapley Additive exPlanations) values provide mathematically rigorous feature attribution, transforming Model 9's ensemble predictions into transparent, dollar-scale explanations as required by F.S. 393.0662. 

This chapter establishes the mathematical foundation of SHAP values and demonstrates their application to Model 9's specific Random Forest implementation—a nonparametric benchmark model using fixed parameters without adaptive optimization.

% ============================================
\section{Mathematical Foundation of SHAP Values}
% ============================================

% --------------------------------------------
\subsection{The Shapley Value from Cooperative Game Theory}
% --------------------------------------------
%
SHAP values originate from Lloyd Shapley's solution concept in cooperative game theory (Shapley, 1953)\footnote{Shapley, L.S. (1953). A value for n-person games. In \textit{Experts Insights}, Santa Monica, CA: RAND Corporation, 1952. \href{https://www.rand.org/pubs/papers/P295.html}{www.rand.org/pubs/papers/P295.html} Accessed on 10/14/2025.}. Consider a coalitional game with $p$ players (features) and a value function $v: 2^p \rightarrow \mathbb{R}$ that maps each coalition $S \subseteq \{1, ..., p\}$ to a real value. The Shapley value $\phi_i$ for player $i$ is:
%
\begin{equation}
\phi_i(v) = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(p - |S| - 1)!}{p!} \left[v(S \cup \{i\}) - v(S)\right]
\label{eq:shapley_original}
\end{equation}
%
where 
\begin{itemize}
    \item $N = \{1, 2, ..., p\}$ is the set of all features,
    \item $S$ is a subset of features not including feature $i$,
    \item $v(S)$ is the value (prediction) using only features in subset $S$,
    \item $|S|$ is the cardinality of set $S$.
\end{itemize}

% --------------------------------------------
\subsection{Adapting Shapley Values to Machine Learning}
% --------------------------------------------

For machine learning models, Lundberg and Lee (2017)\footnote{Lundberg, S.M. and Lee, S.I. (2017). A unified approach to interpreting model predictions. In \textit{NIPS'17: Proceedings of the 31st International Conference on Neural Information Processing Systems}, pages 4768-4777.} adapted Shapley values by defining the value function as the expected model output conditioned on a subset of features:
%
\begin{equation}
v_x(S) \;=\; \mathbb{E}_{X_{\bar S}}\!\big[\,f\big(x_S, X_{\bar S}\big)\,\big]
\label{eq:value_function}
\end{equation}
where 
\begin{itemize}
    \item $X_{\bar S}$ are the features not in $S$ integrated out under a reference distribution (background data), 
     \item $f$ is our trained Random Forest model (static configuration), 
     \item $x$ is the feature vector for a specific consumer, 
     \item $x_S$ contains only the features in subset $S$, 
     \item The expectation is over features not in $S$.
\end{itemize}
%
In trees, TreeSHAP's default is the path-dependent formulation that uses training-data statistics along each path, yielding exact Shapley attributions in polynomial time for tree ensembles.

% --------------------------------------------
\subsection{SHAP Values for Model Interpretation}
% --------------------------------------------

For a consumer with features $x = (x_1, x_2, ..., x_p)$ and Model 9's prediction $f(x)$, the SHAP value $\phi_i$ for feature $i$ represents that feature's contribution to moving the prediction from the baseline to the actual prediction:
%
\begin{equation}
f(x) = \phi_0 + \sum_{i=1}^{p} \phi_i(x)
\label{eq:shap_decomposition}
\end{equation}
%
where $\phi_0 = \mathbb{E}[f(x)]$ is the baseline prediction (mean iBudget allocation across training data).

% --------------------------------------------
\subsection{Properties of SHAP Values}
% --------------------------------------------
SHAP values satisfy four desirable properties ensuring consistent attribution:

\begin{enumerate}
    \item \textbf{Local Accuracy}: The sum of SHAP values equals the prediction minus expected value
    \item \textbf{Missingness}: Absent features contribute zero
    \item \textbf{Consistency}: If a model change increases a feature's marginal contribution to predictions for all coalitions, that feature's SHAP value does not decrease (TreeSHAP preserves this for trees)
    \item \textbf{Symmetry}: Equal contributors receive equal attribution
\end{enumerate}

% ============================================
\section{Model 9 Random Forest Implementation}
% ============================================

% --------------------------------------------
\subsection{Static Model Configuration}
% --------------------------------------------
Model 9 uses a fixed Random Forest configuration without hyperparameter tuning:

\begin{lstlisting}[language=Python, caption=Model 9 Static Configuration (from code)]
RandomForestRegressor(
    n_estimators=150,
    max_depth=15,
    min_samples_split=8,
    min_samples_leaf=3,
    max_features='sqrt',
    bootstrap=True,
    oob_score=True,
    random_state=42,
    n_jobs=-1
)
\end{lstlisting}
This configuration is hard-coded in Model 9 and used consistently in the pipeline (no hyperparameter search). 

Key characteristics:
\begin{itemize}
    \item \textbf{No transformation}: Direct prediction on dollar scale (transformation='none')
    \item \textbf{No outlier removal}: 100\% data retention
    \item \textbf{No adaptive weighting}: Standard bootstrap sampling
    \item \textbf{No hyperparameter search}: Fixed parameters based on domain knowledge
\end{itemize}

% --------------------------------------------
\subsection{Random Forest Prediction Structure}
% --------------------------------------------
Model 9 produces predictions through simple ensemble averaging:
%
\begin{equation}
f_{\text{RF}}(x) = \frac{1}{150} \sum_{b=1}^{150} f_b(x)
\label{eq:rf_prediction}
\end{equation}
%
where $B = \ModelNineNTrees{}$ = 150 trees (actual implementation) and $f_b(x)$ is the prediction from tree $b$. Each tree partitions the feature space using binary splits:
%
\begin{equation}
f_b(x) = \sum_{m=1}^{M_b} c_{bm} \cdot \mathbb{I}(x \in R_{bm})
\label{eq:tree_structure}
\end{equation}
%
where $c_{bm}$ is the mean of training observations in leaf region $R_{bm}$.

% --------------------------------------------
\subsection{Out-of-Bag Validation}
% --------------------------------------------

Model 9 uses OOB validation (not k-fold CV internally):

\begin{equation}
\text{OOB Error}_i = y_i - \frac{1}{|B_i^{\text{OOB}}|} \sum_{b \in B_i^{\text{OOB}}} f_b(x_i)
\label{eq:oob_error}
\end{equation}

where $B_i^{\text{OOB}}$ contains trees where observation $i$ was not in the bootstrap sample. This provides:
\begin{itemize}
    \item OOB R$^2$ = \ModelNineOOBRSquared{}
    \item OOB RMSE = \$\ModelNineOOBError{}
\end{itemize}

% ============================================
\section{TreeSHAP Algorithm for Model 9}
% ============================================

% --------------------------------------------
\subsection{Efficient SHAP Computation for Trees}
% --------------------------------------------

TreeSHAP (Lundberg et al., 2020)\footnote{Lundberg, S.M., Erion, G., Chen, H. et al. From local explanations to global understanding with explainable AI for trees. Nat Mach Intell 2, 56-67 (2020). DOI: \href{https://doi.org/10.1038/s42256-019-0138-9}{10.1038/s42256-019-0138-9}} computes exact SHAP values in polynomial time by exploiting tree structure. For a single decision tree:
%
\begin{equation}
\phi_i^{\text{tree}} = \sum_{\text{paths } P} w_P \cdot \Delta_{i,P}
\label{eq:treeshap_path}
\end{equation}
%
where:
\begin{itemize}
    \item $P$ represents a path from root to leaf
    \item $w_P$ is the proportion of training data following path $P$
    \item $\Delta_{i,P}$ is feature $i$'s contribution along path $P$
\end{itemize}

Intuitively, TreeSHAP sums each feature's marginal contribution along all root-to-leaf paths while weighting by path probabilities computed from training data. We omit the full combinatorial expression, but emphasize that TreeSHAP returns \emph{exact} Shapley values for trees in $O(TLD^2)$ time (trees $T$, average leaves $L$, depth $D$).

% --------------------------------------------
\subsection{Aggregating SHAP Values Across Ensemble}
% --------------------------------------------
For Model 9's ensemble, the final SHAP value for feature $i$ is:
%
\begin{equation}
\phi_i^{\text{RF}} = \frac{1}{150} \sum_{b=1}^{150} \phi_i^{(b)}
\label{eq:rf_shap}
\end{equation}
%
Note: Using 150 trees as implemented in  {\ttfamily model\_9\_random\_forest.py}. This linear aggregation maintains computational efficiency while preserving exact Shapley properties.

% --------------------------------------------
\subsection{Computational Complexity}
% --------------------------------------------
For Model 9 with:
\begin{itemize}
    \item $B = \ModelNineNTrees{}$ trees (150 in implementation)
    \item $D = \ModelNineMaxDepth{}$ maximum depth (15 in implementation)
    \item $L \approx$ 500 average leaves per tree
    \item $p = \ModelNineNumFeatures{}$ features
\end{itemize}
%
Complexity for SHAP explanation computation: $O(B \cdot L \cdot D^2) = O(150 \cdot 500 \cdot 15^2) \approx 1.7 \times 10^7$ elementary operations for a single explanation, which is typically sub-second on standard hardware. This translates to approximately 100-200ms per consumer explanation on standard hardware (not for model training).

% ============================================
\section{Feature Importance vs. SHAP Values}
% ============================================
% --------------------------------------------
\subsection{Impurity-Based Feature Importance (Regression)}
% --------------------------------------------
Model 9's native feature importance uses \emph{variance/MSE impurity reduction} (the regression analogue of Gini for classification):
%
\begin{equation}
    \text{Importance}_i \;=\; \frac{1}{B} \sum_{b=1}^{B} \;\sum_{t \in T_b} \mathbb{I}(v_t = i) \cdot p_t \cdot \Delta I_t,
    \qquad \Delta I_t \equiv I_{\text{parent}} - \big(p_L I_L + p_R I_R\big),
    \label{eq:variance_importance}
\end{equation}
where:
\begin{itemize}
    \item $v_t$ is the splitting variable at node $t$
    \item $p_t$ is the proportion of samples reaching node $t$
    \item $\Delta G_t$ is the weighted Gini impurity decrease
    \item $I$ is node variance (MSE) for regression trees. 
\end{itemize}
%
\textbf{Critical distinctions}: (1) This ranks split usefulness but is \emph{not} directional and is not causal. (2) This measures average reduction in variance impurity, \textbf{not} directional impact or causality; SHAP supplies the signed, per-individual contributions.

% --------------------------------------------
\subsection{SHAP Advantages Over Gini Importance}
% --------------------------------------------
Table \ref{tab:importance_comparison} summarizes the key methodological differences between two approaches to measuring feature importance in tree-based models. The traditional Gini importance reflects only the average magnitude of variable splits within the ensemble, offering a relative ranking of predictors but no direction or individual-level attribution. In contrast, SHAP values provide a mathematically consistent framework that decomposes each prediction into additive feature contributions. This allows directional interpretation (positive or negative impact), person-specific explanations, and explicit accounting for feature interactions, producing results that are more transparent and policy-relevant for the iBudget analytical framework
%
\begin{table}[h]
\centering
\caption{Feature Importance Methods Comparison}
\begin{tabular}{lll}
\toprule
\textbf{Aspect} & \textbf{Gini Importance} & \textbf{SHAP Values} \\
\midrule
Direction & No (magnitude only) & Yes (positive/negative) \\
Individual-level & No (global average) & Yes (per consumer) \\
Interaction effects & Implicit & Explicit \\
Consistency & Tree-dependent & Axiomatically guaranteed \\
Interpretability & Relative ranking & Dollar contributions \\
\bottomrule
\end{tabular}
\label{tab:importance_comparison}
\end{table}

% ============================================
\section{Random Forest Model Object Structure (sklearn)}
% ============================================
% --------------------------------------------
\subsection{Trained Model Components}
% --------------------------------------------
Model 9's serialized object contains structures necessary for SHAP computation:
%
\begin{lstlisting}[language=Python, caption=Random Forest Model Object Structure]
class RandomForestRegressor:
    # Core attributes
    n_estimators = 150          # Number of trees (actual implementation)
    estimators_ = [...]         # List of DecisionTreeRegressor objects
    feature_importances_ = [...] # variance (MSE) impurity decrease (NOT causal)
    oob_score_ = ...            # Out-of-bag R-squared (sklearn computes $R^2$ by default)
    oob_prediction_ = [...]     # OOB predictions for training data
    
    # Each tree contains
    class DecisionTreeRegressor:
        tree_ = Tree object:
            - children_left/right: child node indices
            - feature: splitting feature index
            - threshold: splitting value
            - value: mean response at each node
            - n_node_samples: sample count per node
            - weighted_n_node_samples: weighted counts
\end{lstlisting}

% --------------------------------------------
\subsection{Information Required for SHAP}
% --------------------------------------------
SHAP computation accesses:
%
\begin{enumerate}
    \item \textbf{Tree topology}: \texttt{children\_left}, \texttt{children\_right} for path traversal
    \item \textbf{Split rules}: \texttt{feature} and \texttt{threshold} at each internal node
    \item \textbf{Leaf values}: \texttt{value} array containing predictions
    \item \textbf{Sample statistics}: \texttt{n\_node\_samples/weighted\_n\_node\_samples} for path probability weighting
\end{enumerate}
%
These fields are available from the fitted Model 9 object used in the pipeline.

% ============================================
\section{Computing SHAP Values from Model 9}
% ============================================
% --------------------------------------------
\subsection{Initialization Phase}
% --------------------------------------------
Given Model 9's trained object (no transformation, fixed parameters):
\begin{lstlisting}[language=Python, caption=TreeSHAP initialization for Model 9 (dollar scale)]
import shap
import joblib
import pandas as pd

model_9 = joblib.load(".../model_9/model_9_model.pkl")   # fitted sklearn RF
X_train  = pd.read_parquet(".../model_9/X_train.parquet") # or reconstruct from pipeline

# Sanity-check fixed configuration (as implemented in code)
assert model_9.n_estimators == 150 and model_9.max_depth == 15
assert model_9.min_samples_split == 8 and model_9.min_samples_leaf == 3

# For tree models, TreeSHAP is exact and does not require a background dataset;
# we keep a small background to define the expected value clearly.
bg = X_train.sample(n=min(1000, len(X_train)), random_state=42)
explainer = shap.TreeExplainer(model_9, data=bg, model_output="raw")
\end{lstlisting}
%
Model 9 predicts on the \emph{dollar} scale (no transformation), so SHAP values are in dollars. 

% --------------------------------------------
\subsection{Individual Prediction Explanation}
% --------------------------------------------
For a specific consumer:
%
\begin{lstlisting}[language=Python, caption=Computing SHAP values for one consumer (dollar scale)]
    # Reindex consumer row to match model feature order
    row = (pd.Series({
        'bsum': 15, 'fsum': 12, 'RH3': 1, 'Age31Plus': 1, 'Q26': 3,
        # ... include all features used in Model 9, ordered to match training columns
    })
    .reindex(X_train.columns).to_frame().T)

    phi = explainer.shap_values(row)[0]              # 1D array of contributions in $
    base = float(explainer.expected_value)           # baseline in $
    pred = float(model_9.predict(row)[0])            # RF prediction in $

    # Additivity (allow small numeric tolerance)
    assert abs(base + phi.sum() - pred) < 1e-6
\end{lstlisting}

% --------------------------------------------
\subsection{Practical Allocation Breakdown}
% --------------------------------------------

Example decomposition for a \$72,450 allocation (using 150-tree ensemble):

\begin{align}
\text{Allocation} &= \$40,000 \text{ (baseline mean)} \nonumber \\
&+ \$18,000 \text{ (Living\_RH3 = 1)} \nonumber \\
&+ \$8,500 \text{ (BSum = 15)} \nonumber \\
&+ \$4,200 \text{ (Q26 = 3)} \nonumber \\
&+ \$2,100 \text{ (Age31Plus = 1)} \nonumber \\
&- \$350 \text{ (other features)} \nonumber \\
&= \$72,450 \text{ (final prediction)}
\label{eq:allocation_example}
\end{align}

Note: All values are in dollars (no transformation), directly interpretable for stakeholders.

% ============================================
\section{Model 9 Diagnostic Integration}
% ============================================

% --------------------------------------------
\subsection{Reported Metrics from Implementation}
% --------------------------------------------
Model 9's actual diagnostics (from \texttt{model\_9\_random\_forest.py}):
\begin{table}[h]
\centering
\caption{Model 9 Performance Metrics}
\begin{tabular}{ll}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Training R$^2$ & \ModelNineRSquaredTrain{} \\
Test R$^2$ & \ModelNineRSquaredTest{} \\
Test RMSE & \$\ModelNineRMSETest{} (dollar scale) \\
OOB R$^2$ & \ModelNineOOBRSquared{}\footnote{If value shows "N/A", ensure model\_9\_renewcommands.tex is generated from model\_9\_random\_forest.py} \\
OOB RMSE & \$\ModelNineOOBError{} (dollar scale) \\
Mean Tree Depth & \ModelNineMeanTreeDepth{} \\
Training Time & \ModelNineTrainingTime{} seconds \\
Data Retention & 100\% (no outlier removal) \\
Transformation & None (direct dollar prediction) \\
\bottomrule
\end{tabular}
\label{tab:model9_metrics}
\end{table}

% --------------------------------------------
\subsection{Top Features by Gini Importance}
% --------------------------------------------

Model 9's feature importance (variance reduction, not causal):

\begin{enumerate}
    \item \ModelNineTopFeatureOne{}: \ModelNineTopFeatureOneImportance{} (Gini)
    \item \ModelNineTopFeatureTwo{}: \ModelNineTopFeatureTwoImportance{} (Gini)
    \item \ModelNineTopFeatureThree{}: \ModelNineTopFeatureThreeImportance{} (Gini)
    \item \ModelNineTopFeatureFour{}: \ModelNineTopFeatureFourImportance{} (Gini)
    \item \ModelNineTopFeatureFive{}: \ModelNineTopFeatureFiveImportance{} (Gini)
\end{enumerate}

These reflect split frequency and variance reduction, not directional effects.

% ============================================
\section{Regulatory Compliance Through SHAP}
% ============================================
% --------------------------------------------
\subsection{Meeting F.S. 393.0662 Requirements}
% --------------------------------------------
Florida Statute 393.0662 requires algorithm transparency. SHAP values provide:
%
\begin{enumerate}
    \item \textbf{Individual explanations}: Dollar attribution for each feature
    \item \textbf{Consistency}: Identical features produce identical contributions
    \item \textbf{Completeness}: Full decomposition from baseline to final allocation
    \item \textbf{Auditability}: Axiomatic attribution (local accuracy, missingness, symmetry, consistency) suitable for audit; nevertheless, SHAP is \emph{explanatory}, not causal.
\end{enumerate}

% --------------------------------------------
\subsection{Appeal Process Documentation}
% --------------------------------------------

For allocation appeals, SHAP provides complete documentation:

\begin{itemize}
    \item Baseline allocation (population mean): \$40,000
    \item Individual feature contributions: $\phi_1, ..., \phi_{78}$ in dollars
    \item Final prediction: Sum of baseline plus all contributions
    \item No hidden factors or transformations
\end{itemize}

% ============================================
\section{Limitations and Considerations}
% ============================================
% --------------------------------------------
\subsection{Model 9 Specific Limitations}
% --------------------------------------------
\begin{enumerate}
    \item \textbf{No Causal Interpretation}: SHAP values show correlational contribution, not causation
    \item \textbf{Static Configuration}: No adaptive optimization or fairness constraints applied
    \item \textbf{Ensemble Averaging}: Outlier robustness is implicit through aggregation, not explicit weighting
    \item \textbf{No Transformation}: All predictions and SHAP values on raw dollar scale (Model 9 trains and predicts in dollars)
\end{enumerate}

% --------------------------------------------
\subsection{Computational Considerations}
% --------------------------------------------

\begin{itemize}
    \item \textbf{Storage}: Model object $\approx$50MB (150 trees $\times \approx$500 leaves each)
    \item \textbf{Memory}: Background sample requires $\approx$50MB (1000 consumers $\times$ features)
    \item \textbf{Speed}: 100-200ms per explanation on standard hardware (for SHAP computation, not model training)
    \item \textbf{Scaling}: Linear in number of trees and consumers
\end{itemize}

% ============================================
\section{Conclusion}
% ============================================

SHAP values transform Model 9's static Random Forest ensemble—a nonparametric benchmark using fixed configuration without optimization—into an interpretable system suitable for iBudget allocation. The mathematical rigor of Shapley values, combined with TreeSHAP's computational efficiency, enables transparent explanations while maintaining Model 9's predictive performance (Test R$^2$ = \ModelNineRSquaredTest{}, OOB R$^2$ = \ModelNineOOBRSquared{}).

Model 9's implementation uses:
\begin{itemize}
    \item Fixed parameters (no tuning): 150 trees, max depth 15, min samples split 8, min samples leaf 3
    \item No transformation: Direct dollar-scale predictions
    \item No outlier removal: 100\% data retention
    \item OOB validation: Internal performance assessment
    \item Gini importance: Variance-based feature ranking (non-directional)
\end{itemize}

By applying SHAP to this straightforward Random Forest configuration, Florida APD achieves transparent budget explanations that satisfy regulatory requirements while acknowledging the model's role as a robust, nonparametric alternative to the parametric Models 1-8.