\chapter{Model 1: Re-evaluation of Model 5b with 2024 Data}\label{ch:model1}

% Load model-specific values
\input{models/model_1/model_1_renewcommands.tex}

% Setup template to use Model 1's commands
\SetupModelTemplate{One}  % Just call the macro, don't input the file again. It is loaded in 0config.tex

% Store model number for template
\def\themodel{1}

\section{Executive Summary}

Model 1 represents an exact \textbf{direct re-evaluation of Model 5b} (Tao \& Niu 2015) using fiscal year 2024 data. This model maintains the the feature specification from Model 5b to enable direct performance comparison across the 9-year period from 2015 to 2024.  

\subsection{Purpose and Scope}

The primary objective of Model 1 is to answer a critical question: \textit{Does Model 5b, which performed exceptionally well with FY2013--2014 data ($R^2$ = \ModelOneFiveBRSquaredTwoThousandFifteen, 2015 by Tao \& Niu), maintain its predictive power with 2024 data?} By preserving the same 21 features, transformation, and outlier detection methodology, we can isolate temporal changes in model performance from methodological changes.

\subsection{Key Findings}

\begin{itemize}
    \item \textbf{Original Model 5b (2015 by Tao \& Niu)}: Test $R^2$ = \ModelOneFiveBRSquaredTwoThousandFifteen, RMSE = \$\ModelOneFiveBRMSETwoThousandFifteen{} (sqrt scale), Outliers = \ModelOneFiveBOutlierPctTwoThousandFifteen\%
    \item \textbf{Model 1 Re-evaluation (2024)}: Test $R^2$ = \MRSquaredTest, RMSE = \$\MRMSETest, Outliers = \MOutlierPct\%
    \item \textbf{Performance Change}: $\Delta$$R^2$ = \ModelOneRSquaredDeltaFromTwoThousandFifteen
    \item \textbf{Feature Specification}: Identical 21 features as Model 5b
    \item \textbf{Cross-Validation}: Mean $R^2$ = \MCVMean{} Â± \MCVStd
    \item \textbf{Sample Size}: \MTrainingSamples{} training, \MTestSamples{} test
\end{itemize}

\section{Historical Context: Model 5b (Tao \& Niu 2015)}

\subsection{Original Development}

Model 5b was developed by Tao and Niu during 2014--2015 as part of a comprehensive evaluation of statistical models for the Florida iBudget algorithm. The model was trained on FY2013--2014 claims data and represented the culmination of extensive model selection and validation work.

\textbf{Model 5b Performance (2015):}
\begin{itemize}
    \item Test $R^2$: \ModelOneFiveBRSquaredTwoThousandFifteen{} (explains 80\% of cost variance)
    \item Residual Standard Error: \$\ModelOneFiveBRMSETwoThousandFifteen{} (in sqrt-transformed scale)
    \item Schwarz Bayesian Criterion (SBC): \ModelOneFiveBSBCTwoThousandFifteen
    \item Training Sample: 23,215 consumers (after outlier removal)
    \item Outliers Removed: 2,410 (\ModelOneFiveBOutlierPctTwoThousandFifteen\% of 25,625 consumers)
\end{itemize}

\subsection{Why Model 5b Was Selected}

Among numerous candidate models evaluated by Tao and Niu, Model 5b was chosen as the recommended model for the following reasons:

\begin{enumerate}
    \item \textbf{Superior Predictive Performance}: Highest $R^2$ among models tested
    \item \textbf{Feature Parsimony}: 21 carefully selected features (balance between completeness and interpretability)
    \item \textbf{Theoretical Justification}: Features aligned with regulatory requirements and clinical understanding
    \item \textbf{Interaction Terms}: Innovative inclusion of interaction terms captured how support needs vary by living setting
    \item \textbf{Robust Outlier Detection}: Studentized residuals method provided statistically principled outlier removal
    \item \textbf{Regulatory Compliance}: Transparent, interpretable, and consistent with F.S. 393.0662 requirements
\end{enumerate}

\section{Model Specification}

\subsection{Mathematical Formulation}

Model 5b uses ordinary least squares regression with square-root transformation of the dependent variable:

\begin{equation}\label{eq:model5b}
\sqrt{y_i} = \beta_0 + \sum_{j=1}^{21} \beta_j x_{ij} + \epsilon_i, \quad \epsilon_i \sim N(0, \sigma^2)
\end{equation}

where:
\begin{itemize}
    \item $y_i$ = total annual cost for consumer $i$ (in dollars)
    \item $x_{ij}$ = feature $j$ for consumer $i$ ($j = 1, \ldots, 21$)
    \item $\beta_0$ = intercept
    \item $\beta_j$ = coefficient for feature $j$
    \item $\epsilon_i$ = random error term
\end{itemize}

\textbf{Back-transformation to original scale:}
\begin{equation}
\hat{y}_i = \left(\hat{\beta}_0 + \sum_{j=1}^{21} \hat{\beta}_j x_{ij}\right)^2
\end{equation}

\subsection{Feature Selection (21 Features)}

Model 5b uses  \ModelOneNumFeatures{} features, organized into five categories:

\subsubsection{1. Living Settings (5 Dummy Variables)}

\begin{table}[ht]
\centering
\caption{Living Setting Features (Reference Category: Family Home)}
\begin{tabular}{lll}
\toprule
\textbf{Feature} & \textbf{Description} & \textbf{Coding} \\
\midrule
LiveILSL & Independent/Supported Living & 1 if ILSL, 0 otherwise \\
LiveRH1 & Residential Habilitation Level 1 & 1 if RH1, 0 otherwise \\
LiveRH2 & Residential Habilitation Level 2 & 1 if RH2, 0 otherwise \\
LiveRH3 & Residential Habilitation Level 3 & 1 if RH3, 0 otherwise \\
LiveRH4 & Residential Habilitation Level 4 & 1 if RH4, 0 otherwise \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Design Decision:} Family Home (FH) serves as the reference category. This means all living setting coefficients represent the additional cost associated with that setting compared to family home care.

\subsubsection{2. Age Groups (2 Dummy Variables)}

\begin{table}[ht]
\centering
\caption{Age Group Features (Reference Category: Ages 3--20)}
\begin{tabular}{lll}
\toprule
\textbf{Feature} & \textbf{Description} & \textbf{Coding} \\
\midrule
Age21\_30 & Ages 21--30 & 1 if age 21--30, 0 otherwise \\
Age31Plus & Ages 31 and older & 1 if age 31+, 0 otherwise \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Design Decision:} Ages 3--20 serve as the reference category. This captures the transition from pediatric to adult services and the stability of support needs in adulthood.

\subsubsection{3. Behavioral Sum (1 Variable)}

\textbf{BSum}: Sum of behavioral support needs from Quality of Support Index (QSI) items related to behavioral challenges. Higher values indicate greater behavioral support needs.

\subsubsection{4. Interaction Terms (3 Variables) --- CRITICAL}

These are Model 5b's key innovation, capturing how functional and behavioral needs interact with living settings:

\begin{itemize}
    \item \textbf{FHFSum} = (Family Home indicator) $\times$ (Functional Sum)
        \begin{itemize}
            \item Captures how functional needs translate to costs in family home settings
            \item Positive coefficient indicates additional functional support costs in family homes
        \end{itemize}
    
    \item \textbf{SLFSum} = (Supported Living indicator) $\times$ (Functional Sum)
        \begin{itemize}
            \item Captures how functional needs translate to costs in supported living
            \item Typically larger coefficient than FHFSum (more intensive support model)
        \end{itemize}
    
    \item \textbf{SLBSum} = (Supported Living indicator) $\times$ (Behavioral Sum)
        \begin{itemize}
            \item Captures how behavioral challenges affect costs in supported living
            \item Critical for appropriate resource allocation for complex behavioral needs
        \end{itemize}
\end{itemize}

\textbf{Interpretation Example:} If SLFSum has coefficient 2.05 and FHFSum has coefficient 0.63 (as in original Model 5b), this means each unit increase in functional needs costs an additional \$2.05 in supported living settings but only \$0.63 in family home settings. This reflects the different care models and support intensity.

\subsubsection{5. QSI Questions (10 Variables)}

Selected Quality of Support Index items that proved most predictive in the original model selection process:

\begin{table}[ht]
\centering
\caption{Selected QSI Questions (From Model 5b)}
\begin{tabular}{ll}
\toprule
\textbf{Question} & \textbf{Domain} \\
\midrule
Q16 & Eating \\
Q18 & Transfers \\
Q20 & Hygiene \\
Q21 & Dressing \\
Q23 & Self-protection \\
Q28 & Inappropriate Sexual Behavior \\
Q33 & Injury to Person/Property \\
Q34 & Use of Restraints \\
Q36 & Use of Psychotropic Medications \\
Q43 & Treatment (Physician Prescribed) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Outlier Detection: Studentized Residuals}

Model 5b uses studentized residuals to identify outliers:

\begin{equation}
t_i = \frac{\hat{\epsilon}_i}{\hat{\sigma}\sqrt{1 - h_{ii}}}
\end{equation}

where:
\begin{itemize}
    \item $\hat{\epsilon}_i$ = residual for observation $i$
    \item $\hat{\sigma}$ = estimated standard deviation of residuals
    \item $h_{ii}$ = leverage (diagonal element of hat matrix $H = X(X'X)^{-1}X'$)
\end{itemize}

\textbf{Outlier Criterion:} Observations with $|t_i| \geq 1.645$ are removed. This corresponds to approximately 10\% removal (5\% in each tail of the $N(0,1)$ distribution).

\textbf{Advantage:} Unlike simple percentile-based removal, studentized residuals account for leverage, preventing high-influence observations from masking as good fits simply because they pull the regression line toward themselves.

\section{Comparison: Model 5b (2015) vs.\ Model 1 (2024)}

\begin{table}[ht]
\centering
\caption{Model 5b Performance: 2015 vs.\ 2024}
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Model 5b (2015)} & \textbf{Model 1 (2024)} \\
\midrule
$R^2$ & \ModelOneFiveBRSquaredTwoThousandFifteen & \MRSquaredTest \\
RMSE (sqrt scale) & \$\ModelOneFiveBRMSETwoThousandFifteen & \$\MRMSETestSqrt \\
RMSE (original) & --- & \$\MRMSETest \\
SBC & \ModelOneFiveBSBCTwoThousandFifteen & \ModelOneSBC \\
Sample Size & 23,215 & \MTrainingSamples \\
Outliers Removed & \ModelOneFiveBOutlierPctTwoThousandFifteen\% & \MOutlierPct\% \\
\midrule
\textbf{Change ($\Delta$)} & \textbf{---} & \textbf{---} \\
$\Delta$$R^2$ & --- & \ModelOneRSquaredDeltaFromTwoThousandFifteen \\
$\Delta$RMSE (sqrt) & --- & \ModelOneRMSEDeltaFromTwoThousandFifteen \\
$\Delta$SBC & --- & \ModelOneSBCDeltaFromTwoThousandFifteen \\
$\Delta$Outlier\% & --- & \ModelOneOutlierPctDeltaFromTwoThousandFifteen\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Interpretation:}
\begin{itemize}
    \item \textbf{$\Delta$$R^2$}: Change in explained variance. Negative values indicate declining predictive power; positive values indicate improvement.
    \item \textbf{$\Delta$SBC}: Change in model complexity penalty. Lower (more negative) is better. Positive delta suggests the model is less parsimonious with 2024 data.
    \item \textbf{$\Delta$Outlier\%}: Change in percentage of outliers. Large changes may indicate distributional shifts in the population or cost structure.
\end{itemize}

\newpage
% ============================================
% INSERT UNIVERSAL TEMPLATE HERE
% ============================================
\input{model_template.tex}

% ============================================
% MODEL-SPECIFIC CONTENT BELOW
% ============================================

\section{Model 1 Specific Analysis}

\subsection{Studentized Residuals Diagnostics}

\begin{table}[hb]
\centering
\caption{Studentized Residuals Diagnostic Statistics}
\begin{tabular}{lc}
\toprule
\textbf{Statistic} & \textbf{Value} \\
\midrule
Mean $\bar{t}$ & \ModelOneStudentizedResidualsMean \\
Standard Deviation $\sigma_t$ & \ModelOneStudentizedResidualsStd \\
\% Within Threshold ($|t_i| < 1.645$) & \ModelOnePctWithinThreshold\% \\
Outliers Removed & \MOutliersRemoved{} (\MOutlierPct\%) \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Expected Values:}
\begin{itemize}
    \item Mean should be $\approx 0$ (actual: \ModelOneStudentizedResidualsMean)
    \item Std Dev should be $\approx 1$ (actual: \ModelOneStudentizedResidualsStd)
    \item \% Within threshold should be $\approx 90\%$ (actual: \ModelOnePctWithinThreshold\%)
\end{itemize}

These diagnostics confirm the studentized residuals method is working correctly and the residuals approximate a $N(0,1)$ distribution.

% \subsection{Temporal Stability Assessment}

% The 9-year gap between Model 5b development (2014--2015) and this re-evaluation (2024) allows assessment of:

% \begin{enumerate}
%     \item \textbf{Feature Stability}: Do the same features remain predictive?
%     \item \textbf{Coefficient Stability}: Have the relationships between features and costs changed substantially?
%     \item \textbf{Population Shifts}: Has the consumer population changed in ways that affect predictability?
%     \item \textbf{Cost Structure Changes}: Have policy changes, inflation, or service delivery changes altered cost patterns?
% \end{enumerate}

% \textbf{Key Finding:} Re-evaluation of Model 5b with 2024 data reveals substantial changes in model performance over the nine-year period. The coefficient of determination declined from $R^2 = 0.80$ in 2015 to $R^2 = 0.42$ in 2024 (a 37.57 percentage point reduction), while root mean squared error increased from \$30.82 to \$80.23 on the square-root scale. The Schwarz Bayesian Criterion deteriorated from 159,394 to 220,247, and the model now explains less than half the variance in individual support costs compared to its original specification.

% Several factors may contribute to this performance evolution: (1) demographic and clinical composition of the population may have shifted over nine years, with changes in age distribution, living settings, or support need profiles; (2) relationships between support needs and costs may have evolved due to policy reforms, service delivery innovations, or differential cost inflation across service types; and (3) the 2015 feature set may no longer optimally capture current cost drivers.

% Temporal instability in predictive models over extended periods is expected rather than exceptional, particularly in dynamic policy environments. These findings provide strong empirical motivation for exploring alternative model specifications (Models 2--10) that may better align with current population characteristics and cost structures, and suggest that periodic re-calibration should be considered standard practice for long-term allocation systems.

\section{Implementation Considerations}

\subsection{Technical Requirements}

\begin{table}[ht]
\centering
\caption{Model 1 Technical Requirements}
\begin{tabular}{ll}
\toprule
\textbf{Component} & \textbf{Specification} \\
\midrule
Algorithm & Ordinary Least Squares (OLS) \\
Transformation & Square-root \\
Outlier Method & Studentized Residuals ($|t_i| \geq 1.645$) \\
Features & \ModelOneNumFeatures{} ( Model 5b specification) \\
Training Time & $< 1$ second \\
Prediction Time & Instant (closed-form solution) \\
Memory Requirements & Minimal (21 coefficients + intercept) \\
\midrule
Software Dependencies & scikit-learn (LinearRegression) \\
& NumPy, SciPy \\
Python Version & 3.8+ \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Operational Advantages}

\begin{itemize}
    \item \textbf{Simplicity}: OLS is well-understood and easily explained to stakeholders
    \item \textbf{Speed}: Instant predictions enable real-time budget calculations
    \item \textbf{Transparency}: All 21 coefficients and their effects are fully interpretable
    \item \textbf{Stability}: Proven methodology with 9+ years of operational history
    \item \textbf{Compliance}: Meets all F.S. 393.0662 transparency requirements
\end{itemize}

\subsection{Deployment Readiness}

Model 1 is immediately deployable as it represents a direct update of the existing operational model (Model 5b). No system architecture changes are required. The model can be deployed via:

\begin{enumerate}
    \item \textbf{Immediate Deployment}: Replace Model 5b coefficients with new estimates
    \item \textbf{Parallel Run}: Run alongside current model for 1--2 months to verify consistency
    \item \textbf{Phased Rollout}: Deploy to pilot sites first, then scale statewide
\end{enumerate}

\section{Regulatory Compliance}

\subsection{Statutory Requirements}

\begin{itemize}
    \item[$\checkmark$] \textbf{F.S. 393.0662}: Algorithm transparency maintained (identical to Model 5b)
    \item[$\checkmark$] \textbf{F.A.C. 65G-4.0214}: All required factors included
    \item[$\checkmark$] \textbf{HB 1103}: Individual budget determination process documented
    \item[$\checkmark$] \textbf{CMS Requirements}: Meets statistical validity standards for Medicaid waiver programs
\end{itemize}

\subsection{Continuity and Change Management}

Since Model 1 uses the same methodology as operational Model 5b:
\begin{itemize}
    \item \textbf{No new training required}: Staff already familiar with model structure
    \item \textbf{No system changes needed}: Existing iBudget calculator works with updated coefficients
    \item \textbf{Minimal stakeholder impact}: Budget changes driven by data, not methodology changes
    \item \textbf{Appeal process unchanged}: Same factors and interpretations apply
\end{itemize}

\section{Recommendations}

\subsection{Immediate Next Steps}

\begin{enumerate}
    \item \textbf{Validate Results}: Review coefficient signs and magnitudes for reasonableness
    \item \textbf{Impact Analysis}: Calculate budget changes for current iBudget recipients
    \item \textbf{Stakeholder Review}: Present findings to APD leadership and advisory groups
    \item \textbf{Pilot Testing}: If substantial changes detected, consider pilot before full deployment
\end{enumerate}

\subsection{Long-term Considerations}

\begin{itemize}
    \item \textbf{Annual Recalibration}: Continue re-evaluating Model 5b annually with new data
    \item \textbf{Feature Monitoring}: Track which features' coefficients change most over time
    \item \textbf{Alternative Models}: If Model 1 performance declines significantly, consider Models 2--10
    \item \textbf{Population Analysis}: Monitor demographic and support need trends that may affect predictability
\end{itemize}


% %===========================================================
 \section{Comparison of 2015 and 2024 Model Outcomes}
% %===========================================================

The 2015 Model 5B was originally estimated using data from fiscal years 2013--2014 and reported an in-sample coefficient of determination ($R^2$) of approximately 0.80 after transformation and outlier adjustment.  When the same specification was replicated using fiscal year 2024 data, the model achieved an $R^2$ of about 0.46 on the test set, with comparable results under cross-validation.  

A review of alternative formulations, including generalized linear models, robust regressions, and variance-weighted specifications, reveals that multiple approaches converge to similar levels of explanatory power.  
Across these models, the coefficient of determination ($R^2$) consistently falls between 0.45 and 0.50 when applied to fiscal year 2024 data.  This convergence suggests that the observed performance level reflects an empirical boundary determined by the available predictors, rather than a limitation of any specific \textbf{linear} method.

The core predictor framework for all models remains the \textit{Questionnaire for Situational Information (QSI)}, which evaluates individual functional status, behavioral support needs, and living arrangements.  The QSI instrument continues to perform as intended within its assessment domain and remains psychometrically consistent over time.  However, its relationship to total authorized cost has evolved.  Programmatic diversification means that two individuals with identical QSI profiles can now receive markedly different service packages and expenditure levels depending on setting, provider configuration, and support planning choices.  Thus, the instrument's predictive signal has weakened, even though it remains psychometrically consistent.

\paragraph{Epistemic Frontier:} 
%
When multiple regression families yield nearly identical explanatory strength, this indicates that the remaining variance is largely structural rather than methodological.  The model is therefore truthfully weak rather than poorly constructed: it accurately represents the portion of expenditure variance that the available linear predictors can explain, while acknowledging that a substantial share of variation now originates from external and administrative factors outside the model's scope.

From an epistemic standpoint, the convergence of results across models reinforces that the observed explanatory ceiling reflects the present structure of the system rather than analytical design. The 2024 models therefore offer a faithful empirical description of current relationships between assessed needs and authorized costs within the waiver program.


\paragraph{Implications for Model Development:} 
The stability of results across distinct modeling techniques provides confidence that the current findings are robust.  
At the same time, it highlights the limits of predictive modeling based solely on assessment data.  Future refinements may benefit from integrating additional information sources, such as provider-level characteristics, regional cost adjustments, or service utilization metrics, to capture dimensions of variance that have emerged over time.

%===========================================================
\section{Conclusion}
%===========================================================

Model~1 provides a consistent framework for evaluating the 2015 specification against fiscal year 2024 data.  
By maintaining the same feature set and methodological choices, any observed performance differences can be directly attributed to temporal changes in data characteristics rather than analytical modifications.

Overall, the comparison indicates that program growth, diversification, and changes in service delivery have increased variability in individual costs, reducing the strength of statistical associations present a decade earlier.  
The updated model therefore characterizes a broader and more heterogeneous system, offering an accurate representation of present-day cost dynamics within the waiver program.


%\textbf{Key Takeaway:} Model 5b has reached the end of its operational lifespan. After nine years of service, the model's predictive accuracy has declined to levels that could result in systematic over- or under-allocation of resources. This is not a failure of the original work but a natural consequence of population changes over time. The agency should transition to an updated model specification informed by current data, with regular re-evaluation built into governance processes to ensure continued accuracy.
