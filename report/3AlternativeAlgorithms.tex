%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Alternative Algorithms}  \newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Alternative Algorithms}

The proposed alternative algorithms represent six distinct categories of quantitative approaches, each designed to address specific limitations in the current system while advancing compliance with person-centered planning requirements. Enhanced linear regression approaches focus on updating data sources, improving outlier management, and expanding variable inclusion while maintaining the interpretability advantages of traditional statistical methods. Machine learning ensemble approaches leverage advanced algorithms to capture non-linear relationships and complex interactions while providing transparency through feature importance analysis and prediction explanation techniques.

Hybrid statistical-clinical approaches represent a fundamental reconceptualization of algorithmic design, combining statistical prediction with explicit mechanisms for incorporating clinical judgment and person-centered planning elements. These approaches acknowledge that purely statistical methods may be insufficient for capturing the full complexity of individual needs and preferences that effective disability services require.

Person-centered optimization approaches directly address compliance requirements by formulating budget allocation as a multi-objective optimization problem that balances statistical accuracy with goal alignment and fairness considerations. These methods represent a paradigm shift from prediction-focused algorithms to optimization-focused systems that explicitly incorporate individual preferences and societal equity concerns into the mathematical formulation.

Modern time-aware approaches address temporal validity concerns through dynamic regression methods that adapt coefficients over time and longitudinal models that track individual trajectories. These approaches recognize that both population-level service patterns and individual needs evolve over time, requiring algorithmic systems that can adapt rather than remain static.

Specialized needs-based approaches acknowledge the heterogeneity within disability populations through mixture models that identify distinct subpopulations and support vector regression methods that can accommodate high-dimensional assessment data and non-linear relationships. These approaches recognize that one-size-fits-all algorithms may be inherently inadequate for serving diverse disability populations with varying support requirements and preferences.

\subsection{Advanced Mathematical and Statistical Modeling Approaches}

Given the identified deficiencies, several advanced modeling approaches could substantially improve the analysis of QSI data while addressing the fundamental limitations of the current linear regression framework.

\subsubsection{Regularization Methods for High-Dimensional Data}

The QSI dataset presents a high-dimensional modeling challenge with 125 potential predictors and complex multicollinearity among related assessment items. Regularization methods provide principled approaches to variable selection and coefficient estimation.

\paragraph{LASSO Regression (L1 Regularization)}
LASSO regression addresses the variable selection problem through automatic feature selection:

\begin{equation}
\hat{\beta}_{LASSO} = \arg\min_{\beta} \left\{ \|y - X\beta\|_2^2 + \lambda\|\beta\|_1 \right\}
\end{equation}

where $\lambda$ controls the sparsity penalty, automatically setting irrelevant coefficients to exactly zero. This approach would eliminate the need for ad-hoc variable removal while providing a principled method for identifying the most predictive QSI items.

\paragraph{Ridge Regression (L2 Regularization)}
Ridge regression addresses multicollinearity among QSI items without variable elimination:

\begin{equation}
\hat{\beta}_{Ridge} = \arg\min_{\beta} \left\{ \|y - X\beta\|_2^2 + \lambda\|\beta\|_2^2 \right\}
\end{equation}

This approach shrinks correlated coefficients toward each other, potentially resolving the negative coefficient problem by stabilizing parameter estimates.

\paragraph{Elastic Net Regularization}
Elastic Net combines both L1 and L2 penalties to simultaneously address variable selection and multicollinearity:

\begin{equation}
\hat{\beta}_{EN} = \arg\min_{\beta} \left\{ \|y - X\beta\|_2^2 + \lambda_1\|\beta\|_1 + \lambda_2\|\beta\|_2^2 \right\}
\end{equation}

Given the natural groupings in QSI data, this approach could identify relevant subsets of questions while maintaining stable coefficient estimates.

\subsubsection{Sparse Estimation Techniques}

\paragraph{Adaptive LASSO}
Adaptive LASSO incorporates data-driven weights to reduce bias in coefficient estimation:

\begin{equation}
\hat{\beta}_{AL} = \arg\min_{\beta} \left\{ \|y - X\beta\|_2^2 + \lambda\sum_{j=1}^p w_j|\beta_j| \right\}
\end{equation}

where weights $w_j = 1/|\hat{\beta}_j^{(0)}|^\gamma$ are based on initial consistent estimates, potentially addressing the coefficient sign problems observed in the current models.

\paragraph{Group LASSO}
Given the natural grouping of QSI items into functional, behavioral, and physical domains, Group LASSO enables selection of entire groups:

\begin{equation}
\hat{\beta}_{GL} = \arg\min_{\beta} \left\{ \|y - X\beta\|_2^2 + \lambda\sum_{g=1}^G \sqrt{p_g}\|\beta_g\|_2 \right\}
\end{equation}

This approach could determine whether entire assessment domains should be included or excluded from the allocation algorithm.

\subsubsection{Robust Regression Approaches}

To address the outlier problem without arbitrary data exclusion, robust regression methods provide principled alternatives.

\paragraph{M-Estimation}
M-estimators minimize robust loss functions:

\begin{equation}
\hat{\beta}_{M} = \arg\min_{\beta} \sum_{i=1}^n \rho\left(\frac{y_i - x_i^T\beta}{\sigma}\right)
\end{equation}

Using Huber or Tukey bisquare loss functions $\rho(\cdot)$ that downweight extreme observations rather than excluding them entirely.

\paragraph{Quantile Regression}
Given the apparent heteroscedasticity and non-normal residuals, quantile regression models conditional quantiles rather than means:

\begin{equation}
\hat{\beta}_\tau = \arg\min_{\beta} \sum_{i=1}^n \rho_\tau(y_i - x_i^T\beta)
\end{equation}

where $\rho_\tau(u) = u(\tau - \mathbf{1}_{u<0})$ is the quantile loss function. This approach could model different resource allocation patterns across the support needs distribution.

\subsubsection{Machine Learning Approaches for Nonlinear Relationships}

\paragraph{Random Forest Regression}
Random Forest can capture complex nonlinear relationships and interactions among QSI items:

\begin{equation}
\hat{f}(x) = \frac{1}{B}\sum_{b=1}^B T_b(x)
\end{equation}

where $T_b$ represents individual decision trees trained on bootstrap samples. This approach provides variable importance measures and handles interactions naturally.

\paragraph{Gradient Boosting}
Gradient boosting sequentially builds weak learners to minimize prediction error:

\begin{equation}
F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)
\end{equation}

where $h_m$ minimizes the residual from iteration $m-1$. This approach could identify complex patterns in the QSI data that linear models cannot capture.

\subsubsection{Ordinal Regression Methods}

Given the ordinal nature of QSI responses (0-4 scale), proportional odds models may be more appropriate than treating the data as continuous:

\begin{equation}
\text{logit}(P(Y \leq j|x)) = \alpha_j - x^T\beta
\end{equation}

This approach respects the ordinal structure of the assessment data while potentially improving model fit.

\subsubsection{Hierarchical and Mixed-Effects Models}

To account for potential clustering within service areas or provider organizations:

\begin{equation}
y_{ij} = X_{ij}\beta + Z_{ij}b_i + \epsilon_{ij}
\end{equation}

where $b_i \sim N(0,D)$ represents random effects for cluster $i$. This approach could account for systematic differences in resource allocation patterns across regions or providers.

\subsubsection{Ensemble Methods}

\paragraph{Model Stacking}
Stacking combines multiple base models using a meta-learner:

\begin{equation}
\hat{y} = \alpha_0 + \sum_{k=1}^K \alpha_k \hat{f}_k(x)
\end{equation}

where $\hat{f}_k(x)$ represents predictions from different modeling approaches, potentially combining the strengths of parametric and nonparametric methods.

\paragraph{Bayesian Model Averaging}
BMA incorporates model uncertainty into predictions:

\begin{equation}
\hat{y} = \sum_{k=1}^K P(M_k|\text{data}) \cdot \hat{f}_k(x)
\end{equation}

providing principled uncertainty quantification for resource allocation decisions.

\subsection{Recommendations for Model Development}

Given the complexity of the QSI data and the fundamental deficiencies in the current approach, we recommend a multi-stage modeling strategy:

\begin{enumerate}
    \item \textbf{Baseline Establishment}: Implement cross-validated elastic net regression as a regularized linear baseline, addressing multicollinearity and variable selection issues.
    
    \item \textbf{Nonlinear Enhancement}: Apply gradient boosting to detect and model nonlinear relationships and interactions among QSI variables.
    
    \item \textbf{Robustness Testing}: Evaluate quantile regression and robust methods to assess sensitivity to distributional assumptions and outliers.
    
    \item \textbf{Ensemble Integration}: Combine multiple approaches using stacking or Bayesian model averaging to leverage the strengths of different methodological frameworks.
    
    \item \textbf{Validation Framework}: Implement rigorous cross-validation and holdout testing to ensure model generalizability and prevent overfitting.
\end{enumerate}

This comprehensive approach would address the identified deficiencies while fully utilizing the rich multidimensional structure of the QSI assessment data, providing a more reliable foundation for equitable resource allocation decisions.


\section{Current Algorithm Analysis}

\subsection{Mathematical Formulation}

The current iBudget algorithm (Model 5b) employs a multiple linear regression model with square-root transformation:

\begin{equation}
\sqrt{Y_i} = \beta_0 + \sum_{j=1}^{5} \beta_j^{Live} \cdot Live_{ij} + \sum_{k=1}^{2} \beta_k^{Age} \cdot Age_{ik} + \sum_{l} \beta_l^{QSI} \cdot QSI_{il} + \varepsilon_i
\end{equation}

where:
\begin{itemize}
    \item $Y_i$ represents FY 2013-14 expenditures for individual $i$
    \item $Live_{ij}$ are dummy variables for living settings (Family Home, ILSL, RH1-RH4)
    \item $Age_{ik}$ are age category indicators (21-30, 31+)
    \item $QSI_{il}$ are Questionnaire for Situational Information scores
    \item $\varepsilon_i \sim N(0, \sigma^2)$ are error terms
\end{itemize}

The final budget allocation is computed as:
\begin{equation}
Budget_i = \left(\sum_{j} \hat{\beta}_j \cdot X_{ij}\right)^2 \cdot ApportionmentFactor
\end{equation}

\subsection{Model Performance Metrics}

The current algorithm achieves:
\begin{align}
R^2 &= 0.7998 \\
n_{outliers} &= 2,410 \text{ (9.40\% of sample)} \\
n_{total} &= 25,615 \text{ (after outlier removal)}
\end{align}

\subsection{Critical Mathematical Limitations}

\subsubsection{Outlier Dependency}
The model's performance critically depends on outlier removal:
\begin{equation}
R^2_{full} = 0.7549 \ll R^2_{reduced} = 0.7998
\end{equation}

This indicates the algorithm fails to capture the full distribution of individual needs, particularly for complex cases.

\subsubsection{Temporal Validity Issues}
Using data from fiscal year 2013-14 introduces significant temporal bias:
\begin{equation}
\hat{\beta}_{2025} \neq \hat{\beta}_{2013-14}
\end{equation}

The assumption of parameter stability over 11+ years is statistically untenable given:
\begin{itemize}
    \item Service cost inflation: $\Delta Cost \approx 30\%$ over period
    \item Demographic shifts in disability population
    \item Changes in service delivery models
\end{itemize}

\subsubsection{Transformation Bias}
The square-root transformation creates systematic bias:
\begin{equation}
E[Y_i | X_i] \neq E[\hat{Y}_i^2 | X_i]
\end{equation}

This Jensen's inequality violation leads to consistent underestimation of high-needs individuals.

\section{Compliance Analysis with House Bill 1103}

\subsection{Person-Centered Planning Deficiencies}

The current algorithm violates HB 1103 person-centered requirements through:

\begin{equation}
Utility_i = f(Needs_i, Demographics_i) \not\supset f(Preferences_i, Goals_i, Strengths_i)
\end{equation}

where the algorithm fails to incorporate individual preferences, goals, and strengths as required by statute.

\subsection{Data Currency Violations}

HB 1103 requires "recent expenditure data," but:
\begin{equation}
Age(Data) = 2025 - 2014 = 11 \text{ years} \gg \text{Acceptable threshold}
\end{equation}

\section{Proposed Alternative Algorithms}

\subsection{Enhanced Linear Regression Approaches}

\subsubsection{Algorithm A1: Robust Linear Regression}

\textbf{Mathematical Formulation:}
\begin{equation}
\hat{\beta}_{robust} = \arg\min_{\beta} \sum_{i=1}^{n} \rho\left(\frac{y_i - x_i^T\beta}{\sigma}\right)
\end{equation}

where $\rho(\cdot)$ is a robust loss function (Huber or Tukey bisquare):

\begin{equation}
\rho_{Huber}(u) = \begin{cases}
\frac{1}{2}u^2 & \text{if } |u| \leq c \\
c|u| - \frac{1}{2}c^2 & \text{if } |u| > c
\end{cases}
\end{equation}

\textbf{Python Implementation:}
\begin{lstlisting}
from sklearn.linear_model import HuberRegressor
from sklearn.preprocessing import StandardScaler
import numpy as np

# Robust regression implementation
def robust_ibudget_algorithm(X, y):
    """
    Implements robust linear regression for iBudget allocation
    
    Args:
        X: Feature matrix (n_samples, n_features)
        y: Target expenditures (n_samples,)
    
    Returns:
        Trained robust regression model
    """
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Huber regressor handles outliers without removal
    model = HuberRegressor(epsilon=1.35, alpha=0.0001)
    model.fit(X_scaled, y)
    
    return model, scaler

# Usage example
model, scaler = robust_ibudget_algorithm(qsi_features, expenditures)
predictions = model.predict(scaler.transform(new_features))
\end{lstlisting}

\subsubsection{Algorithm A2: Regularized Regression}

\textbf{Mathematical Formulation:}
\begin{equation}
\hat{\beta}_{LASSO} = \arg\min_{\beta} \left\{\frac{1}{2n}\sum_{i=1}^{n}(y_i - x_i^T\beta)^2 + \lambda\sum_{j=1}^{p}|\beta_j|\right\}
\end{equation}

\begin{equation}
\hat{\beta}_{Ridge} = \arg\min_{\beta} \left\{\frac{1}{2n}\sum_{i=1}^{n}(y_i - x_i^T\beta)^2 + \lambda\sum_{j=1}^{p}\beta_j^2\right\}
\end{equation}

\textbf{Python Implementation:}
\begin{lstlisting}
from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV
from sklearn.model_selection import cross_val_score

def regularized_ibudget_algorithm(X, y, method='elastic'):
    """
    Implements regularized regression for iBudget allocation
    
    Args:
        X: Feature matrix including all QSI variables
        y: Target expenditures
        method: 'lasso', 'ridge', or 'elastic'
    
    Returns:
        Optimized regularized model
    """
    if method == 'lasso':
        model = LassoCV(cv=5, random_state=42)
    elif method == 'ridge':
        model = RidgeCV(cv=5)
    else:  # elastic net
        model = ElasticNetCV(cv=5, random_state=42)
    
    model.fit(X, y)
    
    # Feature importance for transparency
    importance = np.abs(model.coef_)
    feature_importance = dict(zip(range(len(importance)), importance))
    
    return model, feature_importance

# Implementation with QSI features
model, importance = regularized_ibudget_algorithm(qsi_matrix, expenditures)
print(f"Selected features: {np.sum(model.coef_ != 0)} out of {len(model.coef_)}")
\end{lstlisting}

\subsection{Machine Learning Ensemble Approaches}

\subsubsection{Algorithm B1: Random Forest Regression}

\textbf{Mathematical Formulation:}
\begin{equation}
\hat{f}_{RF}(x) = \frac{1}{B}\sum_{b=1}^{B} T_b(x)
\end{equation}

where each tree $T_b$ is trained on bootstrap sample $\mathcal{D}_b$ with random feature subset.

\textbf{Variance Estimation:}
\begin{equation}
\text{Var}[\hat{f}_{RF}(x)] = \frac{1}{B^2}\sum_{b=1}^{B}\text{Var}[T_b(x)]
\end{equation}

\textbf{Python Implementation:}
\begin{lstlisting}
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
import pandas as pd

def random_forest_ibudget_algorithm(X, y, person_centered_features=None):
    """
    Implements Random Forest for iBudget with person-centered planning
    
    Args:
        X: QSI and demographic features
        y: Target expenditures
        person_centered_features: Individual goals/preferences
    
    Returns:
        Optimized Random Forest model with feature importance
    """
    # Combine traditional and person-centered features
    if person_centered_features is not None:
        X_combined = np.hstack([X, person_centered_features])
    else:
        X_combined = X
    
    # Hyperparameter tuning
    param_grid = {
        'n_estimators': [100, 200, 500],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }
    
    rf = RandomForestRegressor(random_state=42)
    rf_tuned = GridSearchCV(rf, param_grid, cv=5, scoring='r2', n_jobs=-1)
    rf_tuned.fit(X_combined, y)
    
    # Feature importance analysis
    importance_df = pd.DataFrame({
        'feature': range(X_combined.shape[1]),
        'importance': rf_tuned.best_estimator_.feature_importances_
    }).sort_values('importance', ascending=False)
    
    # Prediction intervals using quantile forests
    from sklearn.ensemble import RandomForestRegressor
    
    class QuantileRandomForest:
        def __init__(self, **kwargs):
            self.rf = RandomForestRegressor(**kwargs)
            
        def fit(self, X, y):
            self.rf.fit(X, y)
            
        def predict_quantiles(self, X, quantiles=[0.1, 0.5, 0.9]):
            predictions = []
            for estimator in self.rf.estimators_:
                predictions.append(estimator.predict(X))
            
            predictions = np.array(predictions).T
            return np.quantile(predictions, quantiles, axis=1).T
    
    return rf_tuned.best_estimator_, importance_df

# Usage with prediction intervals
rf_model, feature_importance = random_forest_ibudget_algorithm(
    qsi_features, expenditures, person_centered_data
)

# Generate prediction intervals for budget planning
quantile_rf = QuantileRandomForest(n_estimators=500, random_state=42)
quantile_rf.fit(X_train, y_train)
budget_intervals = quantile_rf.predict_quantiles(X_test, [0.1, 0.5, 0.9])
\end{lstlisting}

\subsubsection{Algorithm B2: Gradient Boosting with Custom Objective}

\textbf{Mathematical Formulation:}
\begin{equation}
F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)
\end{equation}

where $h_m(x)$ minimizes:
\begin{equation}
h_m = \arg\min_h \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) + h(x_i))
\end{equation}

\textbf{Custom Person-Centered Loss Function:}
\begin{equation}
L_{PC}(y_i, \hat{y}_i) = \alpha \cdot L_{MSE}(y_i, \hat{y}_i) + \beta \cdot L_{PersonCentered}(goals_i, \hat{y}_i)
\end{equation}

\textbf{Python Implementation:}
\begin{lstlisting}
import xgboost as xgb
import lightgbm as lgb
from sklearn.metrics import mean_squared_error

class PersonCenteredGradientBoosting:
    """
    Custom gradient boosting with person-centered objective function
    """
    def __init__(self, alpha=0.7, beta=0.3):
        self.alpha = alpha  # Weight for prediction accuracy
        self.beta = beta    # Weight for person-centered goals
        
    def person_centered_objective(self, y_pred, y_true):
        """
        Custom objective combining MSE with person-centered goals
        """
        # Standard MSE component
        mse_grad = 2 * (y_pred - y_true.get_label())
        mse_hess = np.ones_like(y_pred) * 2
        
        # Person-centered component (example: goal alignment)
        goal_alignment = self._calculate_goal_alignment(y_pred, y_true)
        pc_grad = self._person_centered_gradient(y_pred, goal_alignment)
        pc_hess = self._person_centered_hessian(y_pred, goal_alignment)
        
        # Combined objective
        grad = self.alpha * mse_grad + self.beta * pc_grad
        hess = self.alpha * mse_hess + self.beta * pc_hess
        
        return grad, hess
    
    def fit(self, X, y, person_centered_goals=None):
        """
        Fit XGBoost model with custom objective
        """
        dtrain = xgb.DMatrix(X, label=y)
        
        params = {
            'objective': self.person_centered_objective,
            'eval_metric': 'rmse',
            'max_depth': 6,
            'learning_rate': 0.1,
            'subsample': 0.8,
            'colsample_bytree': 0.8
        }
        
        self.model = xgb.train(params, dtrain, num_boost_round=1000)
        return self
    
    def predict(self, X):
        dtest = xgb.DMatrix(X)
        return self.model.predict(dtest)

# Alternative implementation with LightGBM
def lightgbm_ibudget_algorithm(X, y, categorical_features=None):
    """
    LightGBM implementation for iBudget allocation
    """
    train_data = lgb.Dataset(X, label=y, categorical_feature=categorical_features)
    
    params = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': 0
    }
    
    model = lgb.train(
        params, 
        train_data, 
        num_boost_round=1000,
        valid_sets=[train_data],
        early_stopping_rounds=100,
        verbose_eval=False
    )
    
    return model

# SHAP values for explainability
import shap

def explain_predictions(model, X_test):
    """
    Generate SHAP explanations for individual predictions
    """
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(X_test)
    
    # Individual explanation
    shap.plots.waterfall(explainer.expected_value, shap_values[0], X_test.iloc[0])
    
    return shap_values

# Usage
pc_gb = PersonCenteredGradientBoosting()
pc_gb.fit(X_train, y_train, person_centered_goals)
predictions = pc_gb.predict(X_test)

# Explainability
shap_values = explain_predictions(pc_gb.model, X_test)
\end{lstlisting}

\subsection{Hybrid Statistical-Clinical Approaches}

\subsubsection{Algorithm C1: Two-Stage Hybrid Model}

\textbf{Mathematical Formulation:}

\textbf{Stage 1 - Base Statistical Model:}
\begin{equation}
\hat{Y}_{base,i} = f_{stat}(QSI_i, Demographics_i, Living_{i})
\end{equation}

\textbf{Stage 2 - Person-Centered Adjustment:}
\begin{equation}
\hat{Y}_{final,i} = \hat{Y}_{base,i} \cdot (1 + \delta_i)
\end{equation}

where:
\begin{equation}
\delta_i = g_{PC}(Goals_i, Preferences_i, Strengths_i, Context_i)
\end{equation}

\textbf{Python Implementation:}
\begin{lstlisting}
from sklearn.base import BaseEstimator, RegressorMixin
import numpy as np

class TwoStageHybridModel(BaseEstimator, RegressorMixin):
    """
    Two-stage hybrid model combining statistical prediction 
    with person-centered adjustments
    """
    
    def __init__(self, base_estimator=None, pc_weight=0.2):
        self.base_estimator = base_estimator or RandomForestRegressor()
        self.pc_weight = pc_weight
        
    def fit(self, X_statistical, y, X_person_centered=None):
        """
        Fit the two-stage model
        
        Args:
            X_statistical: Traditional predictors (QSI, demographics)
            y: Target expenditures
            X_person_centered: Person-centered planning features
        """
        # Stage 1: Statistical model
        self.base_estimator.fit(X_statistical, y)
        base_predictions = self.base_estimator.predict(X_statistical)
        
        # Stage 2: Person-centered adjustment model
        if X_person_centered is not None:
            # Calculate residuals for person-centered modeling
            residuals = y - base_predictions
            relative_residuals = residuals / base_predictions
            
            # Fit adjustment model
            from sklearn.linear_model import Ridge
            self.adjustment_model = Ridge(alpha=1.0)
            self.adjustment_model.fit(X_person_centered, relative_residuals)
            
            self.has_pc_features = True
        else:
            self.has_pc_features = False
            
        return self
    
    def predict(self, X_statistical, X_person_centered=None):
        """
        Generate predictions using both stages
        """
        # Stage 1 predictions
        base_pred = self.base_estimator.predict(X_statistical)
        
        if self.has_pc_features and X_person_centered is not None:
            # Stage 2 adjustments
            adjustments = self.adjustment_model.predict(X_person_centered)
            final_pred = base_pred * (1 + self.pc_weight * adjustments)
        else:
            final_pred = base_pred
            
        return np.maximum(final_pred, 0)  # Ensure non-negative budgets
    
    def get_explanation(self, X_stat, X_pc, individual_idx):
        """
        Provide explanation for individual prediction
        """
        base_pred = self.base_estimator.predict(X_stat[individual_idx:individual_idx+1])
        
        explanation = {
            'base_allocation': base_pred[0],
            'statistical_factors': self._get_statistical_explanation(X_stat[individual_idx]),
        }
        
        if self.has_pc_features and X_pc is not None:
            pc_adjustment = self.adjustment_model.predict(X_pc[individual_idx:individual_idx+1])
            explanation['person_centered_adjustment'] = pc_adjustment[0]
            explanation['final_allocation'] = base_pred[0] * (1 + self.pc_weight * pc_adjustment[0])
        else:
            explanation['final_allocation'] = base_pred[0]
            
        return explanation

# Example usage
def implement_two_stage_model(qsi_data, expenditures, person_centered_data):
    """
    Complete implementation of two-stage model
    """
    model = TwoStageHybridModel(
        base_estimator=RandomForestRegressor(n_estimators=200),
        pc_weight=0.15
    )
    
    model.fit(qsi_data, expenditures, person_centered_data)
    
    # Generate predictions
    predictions = model.predict(qsi_test, pc_test)
    
    # Individual explanations
    explanations = []
    for i in range(len(predictions)):
        exp = model.get_explanation(qsi_test, pc_test, i)
        explanations.append(exp)
    
    return model, predictions, explanations

# Usage
two_stage_model, preds, explanations = implement_two_stage_model(
    qsi_features, expenditures, person_centered_features
)
\end{lstlisting}

\subsubsection{Algorithm C2: Bayesian Hierarchical Model}

\textbf{Mathematical Formulation:}

\textbf{Level 1 (Individual):}
\begin{equation}
Y_{ij} | \theta_j, \sigma^2 \sim N(X_{ij}^T\theta_j, \sigma^2)
\end{equation}

\textbf{Level 2 (Group):}
\begin{equation}
\theta_j | \mu, \Sigma \sim N(\mu, \Sigma)
\end{equation}

\textbf{Level 3 (Population):}
\begin{equation}
\mu \sim N(\mu_0, \Sigma_0), \quad \Sigma \sim IW(\nu_0, S_0)
\end{equation}

\textbf{Python Implementation:}
\begin{lstlisting}
import pymc3 as pm
import numpy as np
import pandas as pd
import theano.tensor as tt

def bayesian_hierarchical_ibudget_model(data, group_var='region'):
    """
    Bayesian hierarchical model for iBudget allocation
    
    Args:
        data: DataFrame with individual-level data
        group_var: Grouping variable (e.g., region, age_group)
    
    Returns:
        PyMC3 model and trace
    """
    # Prepare data
    groups = data[group_var].unique()
    group_idx = data[group_var].map({g: i for i, g in enumerate(groups)}).values
    
    n_groups = len(groups)
    n_obs = len(data)
    n_features = data.select_dtypes(include=[np.number]).shape[1] - 1
    
    with pm.Model() as hierarchical_model:
        # Hyperpriors
        mu_alpha = pm.Normal('mu_alpha', 0, sigma=100)
        sigma_alpha = pm.HalfNormal('sigma_alpha', sigma=100)
        
        mu_beta = pm.Normal('mu_beta', 0, sigma=100, shape=n_features)
        sigma_beta = pm.HalfNormal('sigma_beta', sigma=100, shape=n_features)
        
        # Group-level parameters
        alpha = pm.Normal('alpha', mu=mu_alpha, sigma=sigma_alpha, shape=n_groups)
        beta = pm.Normal('beta', mu=mu_beta, sigma=sigma_beta, shape=(n_groups, n_features))
        
        # Individual-level likelihood
        X = pm.Data('X', data.select_dtypes(include=[np.number]).iloc[:, :-1].values)
        y_obs = pm.Data('y_obs', data.iloc[:, -1].values)
        
        mu = alpha[group_idx] + pm.math.dot(X, beta[group_idx].T).diagonal()
        sigma = pm.HalfNormal('sigma', sigma=50)
        
        likelihood = pm.Normal('y', mu=mu, sigma=sigma, observed=y_obs)
        
        # Sampling
        trace = pm.sample(2000, tune=1000, cores=4, return_inferencedata=True)
    
    return hierarchical_model, trace

# Alternative implementation with Stan (via PyStan)
def stan_hierarchical_model():
    """
    Stan implementation for more complex hierarchical models
    """
    stan_code = """
    data {
        int<lower=0> N;              // number of observations
        int<lower=0> J;              // number of groups
        int<lower=0> K;              // number of predictors
        int<lower=1,upper=J> group[N]; // group indicator
        matrix[N,K] X;               // predictor matrix
        vector[N] y;                 // outcome
    }
    
    parameters {
        real mu_alpha;
        real<lower=0> sigma_alpha;
        vector[K] mu_beta;
        vector<lower=0>[K] sigma_beta;
        
        vector[J] alpha;
        matrix[J,K] beta;
        real<lower=0> sigma;
    }
    
    model {
        // Hyperpriors
        mu_alpha ~ normal(0, 100);
        sigma_alpha ~ normal(0, 50);
        mu_beta ~ normal(0, 10);
        sigma_beta ~ normal(0, 10);
        
        // Group-level priors
        alpha ~ normal(mu_alpha, sigma_alpha);
        for (k in 1:K) {
            beta[,k] ~ normal(mu_beta[k], sigma_beta[k]);
        }
        
        // Likelihood
        for (n in 1:N) {
            y[n] ~ normal(alpha[group[n]] + X[n] * beta[group[n]]', sigma);
        }
    }
    """
    
    return stan_code

# Prediction with uncertainty quantification
def bayesian_predictions_with_uncertainty(model, trace, X_new, group_new):
    """
    Generate predictions with full uncertainty quantification
    """
    with model:
        pm.set_data({'X': X_new, 'group_idx': group_new})
        posterior_pred = pm.sample_posterior_predictive(trace, samples=1000)
    
    # Extract prediction intervals
    predictions = posterior_pred['y']
    
    pred_summary = {
        'mean': np.mean(predictions, axis=0),
        'std': np.std(predictions, axis=0),
        'ci_lower': np.percentile(predictions, 2.5, axis=0),
        'ci_upper': np.percentile(predictions, 97.5, axis=0)
    }
    
    return pred_summary

# Usage example
hierarchical_model, trace = bayesian_hierarchical_ibudget_model(budget_data)
predictions = bayesian_predictions_with_uncertainty(hierarchical_model, trace, X_test, group_test)
\end{lstlisting}

\subsection{Person-Centered Optimization Approaches}

\subsubsection{Algorithm D1: Multi-Objective Optimization}

\textbf{Mathematical Formulation:}

\begin{align}
\min_{\mathbf{b}} \quad & \mathbf{F}(\mathbf{b}) = [f_1(\mathbf{b}), f_2(\mathbf{b}), f_3(\mathbf{b})]^T \\
\text{subject to} \quad & \sum_{i=1}^n b_i \leq B_{total} \\
& b_i \geq b_{min,i} \quad \forall i \\
& g_j(\mathbf{b}) \leq 0 \quad j = 1, \ldots, m
\end{align}

where:
\begin{align}
f_1(\mathbf{b}) &= \sum_{i=1}^n (b_i - \hat{b}_i)^2 \quad \text{(prediction accuracy)} \\
f_2(\mathbf{b}) &= -\sum_{i=1}^n w_i^{goals} \cdot GoalAlignment_i(b_i) \quad \text{(person-centered goals)} \\
f_3(\mathbf{b}) &= \sum_{i=1}^n \sum_{j=1}^n |b_i - b_j| \cdot Similarity_{ij} \quad \text{(fairness)}
\end{align}

\textbf{Python Implementation:}
\begin{lstlisting}
from pymoo.algorithms.moo.nsga2 import NSGA2
from pymoo.core.problem import Problem
from pymoo.optimize import minimize
import numpy as np

class iBudgetMultiObjectiveProblem(Problem):
    """
    Multi-objective optimization problem for iBudget allocation
    """
    
    def __init__(self, predicted_budgets, person_centered_goals, 
                 total_budget, min_budgets=None):
        self.predicted_budgets = predicted_budgets
        self.person_centered_goals = person_centered_goals
        self.total_budget = total_budget
        self.n_individuals = len(predicted_budgets)
        self.min_budgets = min_budgets or np.zeros(self.n_individuals)
        
        super().__init__(
            n_var=self.n_individuals,
            n_obj=3,
            n_constr=1,
            xl=self.min_budgets,
            xu=np.full(self.n_individuals, self.total_budget)
        )
    
    def _evaluate(self, X, out, *args, **kwargs):
        """
        Evaluate the multi-objective functions
        """
        n_solutions = X.shape[0]
        f1 = np.zeros(n_solutions)  # Prediction accuracy
        f2 = np.zeros(n_solutions)  # Person-centered goal alignment
        f3 = np.zeros(n_solutions)  # Fairness measure
        g1 = np.zeros(n_solutions)  # Budget constraint
        
        for i in range(n_solutions):
            budgets = X[i, :]
            
            # Objective 1: Minimize prediction error
            f1[i] = np.sum((budgets - self.predicted_budgets) ** 2)
            
            # Objective 2: Maximize person-centered goal alignment (minimize negative)
            goal_alignment = self._calculate_goal_alignment(budgets)
            f2[i] = -np.sum(goal_alignment)
            
            # Objective 3: Minimize inequality (Gini coefficient)
            f3[i] = self._gini_coefficient(budgets)
            
            # Constraint: Total budget limit
            g1[i] = np.sum(budgets) - self.total_budget
        
        out["F"] = np.column_stack([f1, f2, f3])
        out["G"] = g1.reshape(-1, 1)
    
    def _calculate_goal_alignment(self, budgets):
        """
        Calculate alignment between budgets and person-centered goals
        """
        alignment = np.zeros(len(budgets))
        for i, budget in enumerate(budgets):
            # Example: alignment based on service categories funded
            goals = self.person_centered_goals[i]
            alignment[i] = self._goal_budget_alignment(budget, goals)
        return alignment
    
    def _goal_budget_alignment(self, budget, goals):
        """
        Calculate how well budget aligns with individual goals
        """
        # Simplified alignment calculation
        # In practice, this would involve complex service matching
        target_services = goals.get('preferred_services', [])
        budget_adequacy = min(budget / goals.get('estimated_need', budget), 1.0)
        service_availability = len(target_services) / 10.0  # Normalize
        
        return budget_adequacy * service_availability
    
    def _gini_coefficient(self, budgets):
        """
        Calculate Gini coefficient for fairness assessment
        """
        sorted_budgets = np.sort(budgets)
        n = len(sorted_budgets)
        cumsum = np.cumsum(sorted_budgets)
        return (2 * np.sum((np.arange(1, n + 1) * sorted_budgets))) / (n * cumsum[-1]) - (n + 1) / n

def solve_multi_objective_ibudget(predicted_budgets, person_centered_goals, total_budget):
    """
    Solve the multi-objective iBudget optimization problem
    """
    problem = iBudgetMultiObjectiveProblem(
        predicted_budgets, person_centered_goals, total_budget
    )
    
    algorithm = NSGA2(pop_size=100)
    
    res = minimize(
        problem,
        algorithm,
        ('n_gen', 200),
        verbose=True
    )
    
    # Extract Pareto front solutions
    pareto_solutions = res.X
    pareto_objectives = res.F
    
    return pareto_solutions, pareto_objectives

# Goal programming alternative
from scipy.optimize import minimize as scipy_minimize

def goal_programming_ibudget(predicted_budgets, goals, weights, total_budget):
    """
    Goal programming approach for person-centered budget allocation
    """
    n = len(predicted_budgets)
    
    def objective(x):
        budgets = x[:n]
        pos_dev = x[n:2*n]  # Positive deviations
        neg_dev = x[2*n:3*n]  # Negative deviations
        
        # Weighted sum of deviations from goals
        return np.sum(weights['accuracy'] * (pos_dev + neg_dev) + 
                     weights['goals'] * neg_dev +
                     weights['fairness'] * pos_dev)
    
    def constraints(x):
        budgets = x[:n]
        pos_dev = x[n:2*n]
        neg_dev = x[2*n:3*n]
        
        constraints = []
        
        # Budget constraint
        constraints.append(total_budget - np.sum(budgets))
        
        # Deviation constraints
        for i in range(n):
            target = goals[i]['target_budget']
            constraints.append(budgets[i] - target + neg_dev[i] - pos_dev[i])
        
        return np.array(constraints)
    
    # Initial guess
    x0 = np.concatenate([
        predicted_budgets,
        np.zeros(n),  # positive deviations
        np.zeros(n)   # negative deviations
    ])
    
    # Bounds
    bounds = (
        [(0, total_budget) for _ in range(n)] +  # budgets
        [(0, None) for _ in range(2*n)]          # deviations
    )
    
    result = scipy_minimize(
        objective, x0, method='SLSQP',
        constraints={'type': 'eq', 'fun': constraints},
        bounds=bounds
    )
    
    return result.x[:n]  # Return optimized budgets

# Usage example
pareto_solutions, objectives = solve_multi_objective_ibudget(
    predicted_budgets, person_centered_goals, total_budget_available
)

# Select preferred solution from Pareto front
optimal_budgets = pareto_solutions[0]  # or use decision-making criteria
\end{lstlisting}

\subsubsection{Algorithm D2: Constrained Optimization with Fairness}

\textbf{Mathematical Formulation:}

\begin{align}
\min_{\mathbf{b}} \quad & \sum_{i=1}^n \left(b_i - \hat{b}_i\right)^2 + \lambda \sum_{i=1}^n w_i \left(GoalScore_i - \frac{b_i}{\bar{b}}\right)^2 \\
\text{subject to} \quad & \sum_{i=1}^n b_i = B_{total} \\
& b_i \geq b_{min,i} \quad \forall i \\
& \frac{1}{n_g} \sum_{i \in G_g} b_i \geq \alpha \cdot \bar{b} \quad \forall g \in \{demographic\_groups\} \\
& \left|\frac{1}{n_a} \sum_{i \in A_a} b_i - \frac{1}{n_b} \sum_{i \in A_b} b_i\right| \leq \epsilon \quad \forall a,b \in \{groups\}
\end{align}

\textbf{Python Implementation:}
\begin{lstlisting}
from scipy.optimize import minimize
import cvxpy as cp
import numpy as np

def constrained_fair_ibudget_allocation(predicted_budgets, demographic_groups, 
                                      person_centered_scores, total_budget,
                                      fairness_tolerance=0.1):
    """
    Constrained optimization with fairness constraints
    
    Args:
        predicted_budgets: Initial statistical predictions
        demographic_groups: Group membership for fairness constraints
        person_centered_scores: Individual person-centered alignment scores
        total_budget: Total available budget
        fairness_tolerance: Maximum allowed group budget difference
    
    Returns:
        Optimized budget allocation
    """
    n = len(predicted_budgets)
    unique_groups = np.unique(demographic_groups)
    n_groups = len(unique_groups)
    
    # Decision variable
    budgets = cp.Variable(n, pos=True)
    
    # Objective function
    prediction_error = cp.sum_squares(budgets - predicted_budgets)
    person_centered_alignment = cp.sum(
        cp.multiply(person_centered_scores, 
                   cp.square(budgets - np.mean(predicted_budgets)))
    )
    
    objective = cp.Minimize(
        prediction_error + 0.1 * person_centered_alignment
    )
    
    # Constraints
    constraints = []
    
    # Budget constraint
    constraints.append(cp.sum(budgets) == total_budget)
    
    # Minimum budget constraints
    min_budgets = 0.1 * predicted_budgets  # 10% minimum
    constraints.append(budgets >= min_budgets)
    
    # Fairness constraints between demographic groups
    group_means = []
    for group in unique_groups:
        group_mask = (demographic_groups == group)
        group_indices = np.where(group_mask)[0]
        group_mean = cp.sum(budgets[group_indices]) / np.sum(group_mask)
        group_means.append(group_mean)
    
    # Pairwise fairness constraints
    for i in range(n_groups):
        for j in range(i + 1, n_groups):
            constraints.append(
                cp.abs(group_means[i] - group_means[j]) <= 
                fairness_tolerance * np.mean(predicted_budgets)
            )
    
    # Solve optimization problem
    problem = cp.Problem(objective, constraints)
    problem.solve(solver=cp.OSQP)
    
    if problem.status == cp.OPTIMAL:
        return budgets.value
    else:
        raise ValueError(f"Optimization failed with status: {problem.status}")

# Alternative formulation with robust optimization
def robust_fair_ibudget_allocation(predicted_budgets, uncertainty_sets, 
                                 demographic_groups, total_budget):
    """
    Robust optimization approach handling prediction uncertainty
    """
    n = len(predicted_budgets)
    
    # Decision variables
    budgets = cp.Variable(n, pos=True)
    slack_vars = cp.Variable(n, pos=True)  # For robust constraints
    
    # Worst-case objective considering uncertainty
    worst_case_error = 0
    for i in range(n):
        # Uncertainty set for individual i (e.g., confidence interval)
        uncertainty_radius = uncertainty_sets[i]
        worst_case_error += cp.maximum(
            cp.square(budgets[i] - (predicted_budgets[i] + uncertainty_radius)),
            cp.square(budgets[i] - (predicted_budgets[i] - uncertainty_radius))
        )
    
    objective = cp.Minimize(worst_case_error + cp.sum(slack_vars))
    
    # Constraints with robustness
    constraints = [
        cp.sum(budgets) == total_budget,
        budgets >= 0.05 * total_budget / n,  # Minimum allocation
        slack_vars >= 0
    ]
    
    # Robust fairness constraints
    unique_groups = np.unique(demographic_groups)
    for group in unique_groups:
        group_mask = (demographic_groups == group)
        group_indices = np.where(group_mask)[0]
        
        # Ensure group gets fair share even under uncertainty
        group_min_share = 0.8 * np.sum(predicted_budgets[group_mask])
        constraints.append(
            cp.sum(budgets[group_indices]) >= group_min_share - slack_vars[group_indices[0]]
        )
    
    problem = cp.Problem(objective, constraints)
    problem.solve()
    
    return budgets.value, slack_vars.value

# Fairness auditing function
def audit_allocation_fairness(budgets, demographic_groups, protected_attributes):
    """
    Comprehensive fairness audit of budget allocation
    """
    fairness_metrics = {}
    
    # Statistical parity
    for attr in protected_attributes:
        groups = np.unique(demographic_groups[attr])
        group_means = []
        for group in groups:
            mask = (demographic_groups[attr] == group)
            group_mean = np.mean(budgets[mask])
            group_means.append(group_mean)
        
        fairness_metrics[f'{attr}_statistical_parity'] = {
            'group_means': dict(zip(groups, group_means)),
            'max_difference': max(group_means) - min(group_means),
            'coefficient_variation': np.std(group_means) / np.mean(group_means)
        }
    
    # Equalized opportunity (for different need levels)
    # This would require additional need-level data
    
    return fairness_metrics

# Usage example
optimized_budgets = constrained_fair_ibudget_allocation(
    statistical_predictions, demographic_data, pc_scores, total_budget
)

# Audit the results
fairness_audit = audit_allocation_fairness(
    optimized_budgets, demographic_data, ['age_group', 'disability_type', 'region']
)
\end{lstlisting}

\subsection{Modern Time-Aware Approaches}

\subsubsection{Algorithm E1: Dynamic Regression with Time Effects}

\textbf{Mathematical Formulation:}

\textbf{Time-Varying Coefficient Model:}
\begin{equation}
Y_{it} = X_{it}^T \beta_t + \varepsilon_{it}
\end{equation}

where coefficients evolve as:
\begin{equation}
\beta_t = \beta_{t-1} + \omega_t, \quad \omega_t \sim N(0, Q)
\end{equation}

\textbf{State-Space Representation:}
\begin{align}
\beta_t &= F\beta_{t-1} + \omega_t \quad \text{(State equation)} \\
Y_t &= H_t\beta_t + \varepsilon_t \quad \text{(Observation equation)}
\end{align}

\textbf{Python Implementation:}
\begin{lstlisting}
from statsmodels.tsa.statespace import MLEModel
from scipy.linalg import block_diag
import numpy as np
import pandas as pd

class DynamicRegressioniBudget(MLEModel):
    """
    Dynamic regression model for iBudget allocation with time-varying coefficients
    """
    
    def __init__(self, endog, exog, **kwargs):
        self.k_exog = exog.shape[1]
        
        # Initialize state space model
        super().__init__(
            endog, 
            k_states=self.k_exog,
            k_posdef=self.k_exog,
            **kwargs
        )
        
        self.exog = exog
        
        # Initialize state space matrices
        self._initialize_state_space()
    
    def _initialize_state_space(self):
        """
        Initialize state space representation
        """
        # Transition matrix (random walk for coefficients)
        self['transition'] = np.eye(self.k_exog)
        
        # Selection matrix
        self['selection'] = np.eye(self.k_exog)
        
        # Initial state covariance
        self['state_cov'] = np.eye(self.k_exog)
        
    def update(self, params, **kwargs):
        """
        Update state space matrices with current parameters
        """
        # Parameter mapping
        obs_var = params[0]
        state_vars = params[1:1+self.k_exog]
        
        # Update observation equation
        self['obs_intercept'] = 0
        self['design'] = self.exog
        self['obs_cov'] = obs_var
        
        # Update state equation
        self['state_cov'] = np.diag(state_vars)
        
    @property
    def param_names(self):
        return ['obs_var'] + [f'state_var_{i}' for i in range(self.k_exog)]
    
    @property
    def start_params(self):
        return [1.0] + [0.1] * self.k_exog

def fit_dynamic_ibudget_model(expenditure_data, qsi_features, time_index):
    """
    Fit dynamic regression model to iBudget data
    
    Args:
        expenditure_data: Time series of expenditures
        qsi_features: QSI features over time
        time_index: Time index for observations
    
    Returns:
        Fitted model and time-varying coefficients
    """
    # Prepare data
    endog = expenditure_data.values
    exog = qsi_features.values
    
    # Fit model
    model = DynamicRegressioniBudget(endog, exog)
    results = model.fit()
    
    # Extract time-varying coefficients
    states = results.states.filtered
    time_varying_coeffs = pd.DataFrame(
        states.T, 
        index=time_index,
        columns=[f'coeff_{i}' for i in range(qsi_features.shape[1])]
    )
    
    return results, time_varying_coeffs

# Alternative implementation with rolling regression
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

def rolling_regression_ibudget(data, window_size=12, min_periods=6):
    """
    Rolling regression approach for time-adaptive iBudget algorithm
    """
    results = []
    
    for i in range(min_periods, len(data)):
        start_idx = max(0, i - window_size)
        end_idx = i + 1
        
        # Extract window data
        window_data = data.iloc[start_idx:end_idx]
        X = window_data.drop('expenditure', axis=1)
        y = window_data['expenditure']
        
        # Fit model on window
        model = LinearRegression()
        model.fit(X, y)
        
        # Store results
        result = {
            'date': data.index[i],
            'coefficients': model.coef_,
            'intercept': model.intercept_,
            'r2': model.score(X, y),
            'mse': mean_squared_error(y, model.predict(X))
        }
        results.append(result)
    
    return pd.DataFrame(results)

# Inflation adjustment mechanism
def adjust_for_inflation(historical_budgets, inflation_rates, base_year=2024):
    """
    Adjust historical budget data for inflation
    """
    adjusted_budgets = historical_budgets.copy()
    
    for year, rate in inflation_rates.items():
        if year != base_year:
            adjustment_factor = (1 + rate) ** (base_year - year)
            year_mask = adjusted_budgets.index.year == year
            adjusted_budgets.loc[year_mask] *= adjustment_factor
    
    return adjusted_budgets

# Forecasting future budget needs
from statsmodels.tsa.arima.model import ARIMA

def forecast_budget_trends(time_series_data, horizon=12):
    """
    Forecast future budget trends using ARIMA
    """
    forecasts = {}
    
    for column in time_series_data.columns:
        # Fit ARIMA model
        model = ARIMA(time_series_data[column], order=(1, 1, 1))
        fitted_model = model.fit()
        
        # Generate forecasts
        forecast = fitted_model.forecast(steps=horizon)
        conf_int = fitted_model.get_forecast(steps=horizon).conf_int()
        
        forecasts[column] = {
            'forecast': forecast,
            'lower_bound': conf_int.iloc[:, 0],
            'upper_bound': conf_int.iloc[:, 1]
        }
    
    return forecasts

# Usage example
dynamic_model, time_coeffs = fit_dynamic_ibudget_model(
    expenditure_time_series, qsi_time_series, date_index
)

# Rolling regression for comparison
rolling_results = rolling_regression_ibudget(combined_time_series_data)

# Forecast future needs
budget_forecasts = forecast_budget_trends(historical_budget_data)
\end{lstlisting}

\subsubsection{Algorithm E2: Longitudinal Mixed-Effects Model}

\textbf{Mathematical Formulation:}

\textbf{Mixed-Effects Model:}
\begin{equation}
Y_{ij} = X_{ij}^T\beta + Z_{ij}^T b_i + \varepsilon_{ij}
\end{equation}

where:
\begin{align}
b_i &\sim N(0, G) \quad \text{(Random effects)} \\
\varepsilon_{ij} &\sim N(0, R_{ij}) \quad \text{(Within-individual errors)}
\end{align}

\textbf{Individual Growth Curves:}
\begin{equation}
Y_{ij} = \beta_0 + \beta_1 t_{ij} + \beta_2 t_{ij}^2 + b_{0i} + b_{1i}t_{ij} + \varepsilon_{ij}
\end{equation}

\textbf{Python Implementation:}
\begin{lstlisting}
import statsmodels.api as sm
from statsmodels.regression.mixed_linear_model import MixedLM
import numpy as np
import pandas as pd

def longitudinal_ibudget_model(data, individual_id='client_id', time_var='time'):
    """
    Longitudinal mixed-effects model for iBudget needs prediction
    
    Args:
        data: Panel data with repeated observations per individual
        individual_id: Column name for individual identifier
        time_var: Column name for time variable
    
    Returns:
        Fitted mixed-effects model
    """
    # Prepare fixed effects design matrix
    fixed_effects = ['age', 'qsi_behavioral_sum', 'qsi_functional_sum', 
                    'qsi_physical_sum', time_var, f'{time_var}_squared']
    
    # Add squared time term
    data[f'{time_var}_squared'] = data[time_var] ** 2
    
    # Fit mixed-effects model
    model = MixedLM(
        endog=data['expenditure'],
        exog=data[fixed_effects],
        groups=data[individual_id],
        exog_re=data[[time_var]]  # Random slope for time
    )
    
    results = model.fit()
    return results

# Alternative implementation with scikit-learn style
from sklearn.base import BaseEstimator, RegressorMixin
from sklearn.linear_model import LinearRegression

class LongitudinaliBudgetPredictor(BaseEstimator, RegressorMixin):
    """
    Longitudinal predictor for individual budget trajectories
    """
    
    def __init__(self, max_time_horizon=5):
        self.max_time_horizon = max_time_horizon
        self.individual_models = {}
        self.population_model = None
        
    def fit(self, X, y, individual_ids, time_points):
        """
        Fit individual trajectory models
        
        Args:
            X: Feature matrix
            y: Target expenditures
            individual_ids: Individual identifiers
            time_points: Time points for observations
        """
        # Fit population-level model
        X_with_time = np.column_stack([X, time_points, time_points**2])
        self.population_model = LinearRegression()
        self.population_model.fit(X_with_time, y)
        
        # Fit individual models for those with sufficient data
        unique_individuals = np.unique(individual_ids)
        
        for ind_id in unique_individuals:
            mask = individual_ids == ind_id
            if np.sum(mask) >= 3:  # Need at least 3 observations
                X_ind = X[mask]
                y_ind = y[mask]
                t_ind = time_points[mask]
                
                # Individual trajectory model
                X_ind_with_time = np.column_stack([X_ind, t_ind, t_ind**2])
                ind_model = LinearRegression()
                ind_model.fit(X_ind_with_time, y_ind)
                
                self.individual_models[ind_id] = {
                    'model': ind_model,
                    'last_observation_time': np.max(t_ind),
                    'last_features': X_ind[-1],
                    'trajectory_slope': ind_model.coef_[-2]  # Linear time coefficient
                }
        
        return self
    
    def predict_trajectory(self, individual_id, future_time_points, 
                          latest_features=None):
        """
        Predict future trajectory for an individual
        """
        if individual_id in self.individual_models:
            # Use individual model
            ind_info = self.individual_models[individual_id]
            model = ind_info['model']
            
            if latest_features is None:
                latest_features = ind_info['last_features']
            
            # Create prediction matrix
            n_points = len(future_time_points)
            X_pred = np.tile(latest_features, (n_points, 1))
            X_pred = np.column_stack([
                X_pred, 
                future_time_points, 
                future_time_points**2
            ])
            
            return model.predict(X_pred)
        else:
            # Use population model
            n_points = len(future_time_points)
            if latest_features is None:
                # Use population averages
                latest_features = np.mean(self.population_model.coef_[:-2])
            
            X_pred = np.tile(latest_features, (n_points, 1))
            X_pred = np.column_stack([
                X_pred,
                future_time_points,
                future_time_points**2
            ])
            
            return self.population_model.predict(X_pred)
    
    def identify_high_risk_individuals(self, threshold_slope=100):
        """
        Identify individuals with rapidly increasing needs
        """
        high_risk = []
        
        for ind_id, info in self.individual_models.items():
            if info['trajectory_slope'] > threshold_slope:
                high_risk.append({
                    'individual_id': ind_id,
                    'slope': info['trajectory_slope'],
                    'last_time': info['last_observation_time']
                })
        
        return sorted(high_risk, key=lambda x: x['slope'], reverse=True)

# Survival analysis for service transitions
from lifelines import CoxPHFitter

def service_transition_analysis(data, duration_col='time_to_transition',
                              event_col='transitioned'):
    """
    Analyze transitions between service levels using survival analysis
    """
    # Prepare data for Cox regression
    cph = CoxPHFitter()
    
    # Fit Cox proportional hazards model
    cph.fit(
        data, 
        duration_col=duration_col, 
        event_col=event_col
    )
    
    return cph

# Longitudinal clustering for trajectory identification
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

def identify_trajectory_patterns(longitudinal_data, n_clusters=5):
    """
    Identify common trajectory patterns in budget needs
    """
    # Reshape data for clustering (individuals x time points)
    pivot_data = longitudinal_data.pivot_table(
        index='client_id', 
        columns='time', 
        values='expenditure'
    ).fillna(method='ffill').fillna(method='bfill')
    
    # Standardize trajectories
    scaler = StandardScaler()
    scaled_trajectories = scaler.fit_transform(pivot_data)
    
    # Cluster trajectories
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    trajectory_clusters = kmeans.fit_predict(scaled_trajectories)
    
    # Analyze cluster characteristics
    cluster_profiles = {}
    for cluster_id in range(n_clusters):
        mask = trajectory_clusters == cluster_id
        cluster_data = pivot_data.iloc[mask]
        
        cluster_profiles[cluster_id] = {
            'n_individuals': np.sum(mask),
            'mean_trajectory': cluster_data.mean(axis=0),
            'std_trajectory': cluster_data.std(axis=0),
            'trend': 'increasing' if cluster_data.iloc[:, -1].mean() > cluster_data.iloc[:, 0].mean() else 'stable'
        }
    
    return trajectory_clusters, cluster_profiles

# Usage example
longitudinal_model = longitudinal_ibudget_model(panel_data)

# Individual trajectory prediction
trajectory_predictor = LongitudinaliBudgetPredictor()
trajectory_predictor.fit(X_features, expenditures, client_ids, time_points)

# Predict future needs
future_times = np.array([1, 2, 3, 4, 5])  # Next 5 time periods
individual_forecast = trajectory_predictor.predict_trajectory('client_123', future_times)

# Identify high-risk individuals
high_risk_clients = trajectory_predictor.identify_high_risk_individuals()
\end{lstlisting}

\subsection{Specialized Needs-Based Approaches}

\subsubsection{Algorithm F1: Latent Class Mixture Model}

\textbf{Mathematical Formulation:}

\textbf{Mixture Model:}
\begin{equation}
f(y_i | x_i, \Theta) = \sum_{k=1}^{K} \pi_k f_k(y_i | x_i, \theta_k)
\end{equation}

where:
\begin{align}
\pi_k &= P(\text{Individual } i \text{ belongs to class } k) \\
f_k(y_i | x_i, \theta_k) &= \text{Class-specific density function}
\end{align}

\textbf{EM Algorithm for Estimation:}

\textbf{E-step:}
\begin{equation}
\gamma_{ik} = \frac{\pi_k f_k(y_i | x_i, \theta_k)}{\sum_{j=1}^{K} \pi_j f_j(y_i | x_i, \theta_j)}
\end{equation}

\textbf{M-step:}
\begin{align}
\pi_k^{(new)} &= \frac{1}{n}\sum_{i=1}^{n} \gamma_{ik} \\
\theta_k^{(new)} &= \arg\max_{\theta_k} \sum_{i=1}^{n} \gamma_{ik} \log f_k(y_i | x_i, \theta_k)
\end{align}

\textbf{Python Implementation:}
\begin{lstlisting}
from sklearn.mixture import GaussianMixture
from sklearn.linear_model import LinearRegression
import numpy as np
import pandas as pd

class LatentClassiBudgetModel:
    """
    Latent class mixture model for iBudget allocation
    """
    
    def __init__(self, n_classes=4, max_iter=100, random_state=42):
        self.n_classes = n_classes
        self.max_iter = max_iter
        self.random_state = random_state
        self.class_models = {}
        self.mixture_model = None
        self.class_interpretations = {}
        
    def fit(self, X, y, feature_names=None):
        """
        Fit latent class mixture model
        
        Args:
            X: Feature matrix (QSI scores, demographics)
            y: Target expenditures
            feature_names: Names of features for interpretation
        """
        # Step 1: Initial clustering to identify latent classes
        initial_gmm = GaussianMixture(
            n_components=self.n_classes,
            random_state=self.random_state
        )
        
        # Use both features and outcomes for clustering
        clustering_data = np.column_stack([X, y.reshape(-1, 1)])
        class_assignments = initial_gmm.fit_predict(clustering_data)
        
        # Step 2: Fit class-specific regression models
        for k in range(self.n_classes):
            class_mask = (class_assignments == k)
            X_class = X[class_mask]
            y_class = y[class_mask]
            
            if len(y_class) > 10:  # Minimum samples for stable estimation
                model = LinearRegression()
                model.fit(X_class, y_class)
                
                self.class_models[k] = {
                    'model': model,
                    'n_samples': len(y_class),
                    'mean_expenditure': np.mean(y_class),
                    'mean_features': np.mean(X_class, axis=0)
                }
        
        # Step 3: Final mixture model for class assignment
        self.mixture_model = GaussianMixture(
            n_components=len(self.class_models),
            random_state=self.random_state
        )
        self.mixture_model.fit(X)
        
        # Step 4: Interpret classes
        self._interpret_classes(X, y, feature_names)
        
        return self
    
    def _interpret_classes(self, X, y, feature_names):
        """
        Generate interpretations for each latent class
        """
        if feature_names is None:
            feature_names = [f'feature_{i}' for i in range(X.shape[1])]
        
        for k, class_info in self.class_models.items():
            mean_features = class_info['mean_features']
            mean_expenditure = class_info['mean_expenditure']
            
            # Identify distinguishing features
            overall_means = np.mean(X, axis=0)
            feature_deviations = mean_features - overall_means
            
            # Find most distinctive features
            top_features = np.argsort(np.abs(feature_deviations))[-5:]
            
            interpretation = {
                'class_size': class_info['n_samples'],
                'avg_expenditure': mean_expenditure,
                'distinguishing_features': [
                    {
                        'feature': feature_names[i],
                        'class_mean': mean_features[i],
                        'overall_mean': overall_means[i],
                        'deviation': feature_deviations[i]
                    }
                    for i in top_features
                ]
            }
            
            self.class_interpretations[k] = interpretation
    
    def predict(self, X):
        """
        Predict expenditures using mixture of class-specific models
        """
        # Get class probabilities
        class_probs = self.mixture_model.predict_proba(X)
        
        predictions = np.zeros(len(X))
        
        for i, x in enumerate(X):
            class_prediction = 0
            for k, class_info in self.class_models.items():
                if k < len(class_probs[i]):
                    class_pred = class_info['model'].predict(x.reshape(1, -1))[0]
                    class_prediction += class_probs[i][k] * class_pred
            
            predictions[i] = class_prediction
        
        return predictions
    
    def assign_class(self, X):
        """
        Assign individuals to most likely class
        """
        return self.mixture_model.predict(X)
    
    def get_class_interpretation(self, class_id):
        """
        Get human-readable interpretation of a class
        """
        return self.class_interpretations.get(class_id, "Class not found")

# Usage example
latent_class_model = LatentClassiBudgetModel(n_classes=5)
latent_class_model.fit(qsi_features, expenditures, qsi_feature_names)

# Make predictions
predictions = latent_class_model.predict(qsi_test)

# Assign individuals to classes
class_assignments = latent_class_model.assign_class(qsi_test)

# Interpret classes
for class_id in range(5):
    interpretation = latent_class_model.get_class_interpretation(class_id)
    print(f"Class {class_id}: {interpretation}")
\end{lstlisting}

\subsubsection{Algorithm F2: Support Vector Regression}

\textbf{Mathematical Formulation:}

\textbf{SVR Optimization Problem:}
\begin{align}
\min_{w,b,\xi,\xi^*} \quad & \frac{1}{2}\|w\|^2 + C\sum_{i=1}^{n}(\xi_i + \xi_i^*) \\
\text{subject to} \quad & y_i - w^T\phi(x_i) - b \leq \epsilon + \xi_i \\
& w^T\phi(x_i) + b - y_i \leq \epsilon + \xi_i^* \\
& \xi_i, \xi_i^* \geq 0
\end{align}

\textbf{Dual Formulation:}
\begin{equation}
f(x) = \sum_{i=1}^{n}(\alpha_i - \alpha_i^*)K(x_i, x) + b
\end{equation}

where $K(x_i, x_j) = \phi(x_i)^T\phi(x_j)$ is the kernel function.

\textbf{Python Implementation:}
\begin{lstlisting}
from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
import numpy as np

class SVRiBudgetAllocator:
    """
    Support Vector Regression for iBudget allocation
    """
    
    def __init__(self, kernel='rbf', multi_output=False):
        self.kernel = kernel
        self.multi_output = multi_output
        self.models = {}
        self.scaler = StandardScaler()
        self.is_fitted = False
        
    def fit(self, X, y, service_categories=None):
        """
        Fit SVR model(s)
        
        Args:
            X: Feature matrix
            y: Target expenditures (total or by category)
            service_categories: If provided, fit separate models for each category
        """
        X_scaled = self.scaler.fit_transform(X)
        
        if self.multi_output and service_categories is not None:
            # Fit separate SVR for each service category
            unique_categories = np.unique(service_categories)
            
            for category in unique_categories:
                # Parameter grid for optimization
                param_grid = {
                    'C': [0.1, 1, 10, 100],
                    'epsilon': [0.01, 0.1, 0.2],
                    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]
                }
                
                svr = SVR(kernel=self.kernel)
                grid_search = GridSearchCV(
                    svr, param_grid, cv=5, scoring='r2', n_jobs=-1
                )
                
                # Extract category-specific targets
                category_mask = service_categories == category
                y_category = y[category_mask] if len(y.shape) == 1 else y[:, category]
                
                grid_search.fit(X_scaled, y_category)
                self.models[category] = grid_search.best_estimator_
        
        else:
            # Single SVR model
            param_grid = {
                'svr__C': [0.1, 1, 10, 100, 1000],
                'svr__epsilon': [0.01, 0.1, 0.2, 0.5],
                'svr__gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1]
            }
            
            pipeline = Pipeline([
                ('scaler', StandardScaler()),
                ('svr', SVR(kernel=self.kernel))
            ])
            
            grid_search = GridSearchCV(
                pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1
            )
            
            grid_search.fit(X, y)
            self.models['total'] = grid_search.best_estimator_
        
        self.is_fitted = True
        return self
    
    def predict(self, X):
        """
        Generate predictions
        """
        if not self.is_fitted:
            raise ValueError("Model must be fitted before prediction")
        
        if len(self.models) == 1 and 'total' in self.models:
            return self.models['total'].predict(X)
        else:
            # Multi-output prediction
            predictions = {}
            X_scaled = self.scaler.transform(X)
            
            for category, model in self.models.items():
                predictions[category] = model.predict(X_scaled)
            
            return predictions

# Usage example
svr_allocator = SVRiBudgetAllocator(kernel='rbf', multi_output=True)
svr_allocator.fit(qsi_features, expenditures, service_categories)

# Make predictions
svr_predictions = svr_allocator.predict(qsi_test)
\end{lstlisting}

\section{Implementation Framework and Validation}

\subsection{Model Selection Criteria}

For algorithm selection, we propose a comprehensive evaluation framework:

\textbf{Performance Metrics:}
\begin{align}
RMSE &= \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2} \\
MAPE &= \frac{1}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right| \times 100\% \\
R^2_{adj} &= 1 - \frac{(1-R^2)(n-1)}{n-p-1}
\end{align}

\textbf{Fairness Metrics:}
\begin{align}
\text{Statistical Parity} &= \max_{g,h} |E[\hat{Y}|G=g] - E[\hat{Y}|G=h]| \\
\text{Equalized Opportunity} &= \max_{g,h} |P(\hat{Y}>t|Y>t,G=g) - P(\hat{Y}>t|Y>t,G=h)|
\end{align}

\textbf{Person-Centered Compliance Score:}
\begin{equation}
PCC = \frac{1}{n}\sum_{i=1}^{n} \text{GoalAlignment}_i(\hat{Y}_i, Goals_i, Preferences_i)
\end{equation}

\subsection{Validation Framework}

\begin{lstlisting}
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

def comprehensive_algorithm_validation(models, X, y, temporal_data=None):
    """
    Comprehensive validation framework for iBudget algorithms
    """
    validation_results = {}
    
    for name, model in models.items():
        print(f"Validating {name}...")
        
        # Time series validation if temporal data available
        if temporal_data is not None:
            tscv = TimeSeriesSplit(n_splits=5)
            cv_scores = []
            
            for train_idx, test_idx in tscv.split(X):
                X_train, X_test = X[train_idx], X[test_idx]
                y_train, y_test = y[train_idx], y[test_idx]
                
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                
                cv_scores.append({
                    'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
                    'r2': r2_score(y_test, y_pred),
                    'mape': np.mean(np.abs((y_test - y_pred) / y_test)) * 100
                })
            
            validation_results[name] = {
                'temporal_cv': cv_scores,
                'mean_rmse': np.mean([s['rmse'] for s in cv_scores]),
                'mean_r2': np.mean([s['r2'] for s in cv_scores]),
                'mean_mape': np.mean([s['mape'] for s in cv_scores])
            }
        
        else:
            # Standard cross-validation
            cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')
            validation_results[name] = {
                'cv_r2_mean': np.mean(cv_scores),
                'cv_r2_std': np.std(cv_scores)
            }
    
    return validation_results

def fairness_audit_framework(predictions, demographics, protected_attributes):
    """
    Comprehensive fairness auditing
    """
    fairness_results = {}
    
    for attr in protected_attributes:
        groups = np.unique(demographics[attr])
        group_stats = {}
        
        for group in groups:
            mask = demographics[attr] == group
            group_stats[group] = {
                'mean_prediction': np.mean(predictions[mask]),
                'std_prediction': np.std(predictions[mask]),
                'n_individuals': np.sum(mask)
            }
        
        # Calculate statistical parity difference
        group_means = [stats['mean_prediction'] for stats in group_stats.values()]
        statistical_parity = max(group_means) - min(group_means)
        
        fairness_results[attr] = {
            'group_statistics': group_stats,
            'statistical_parity_difference': statistical_parity,
            'coefficient_of_variation': np.std(group_means) / np.mean(group_means)
        }
    
    return fairness_results
\end{lstlisting}

\section{Recommendations and Implementation Roadmap}

\subsection{Phased Implementation Approach}

\textbf{Phase 1: Foundation Models}
\begin{itemize}
    \item Implement Algorithm A1 (Robust Linear Regression)
    \item Implement Algorithm B1 (Random Forest)
    \item Establish validation framework
    \item Compare against current Model 5b
\end{itemize}

\textbf{Phase 2: Advanced Approaches}
\begin{itemize}
    \item Deploy Algorithm C1 (Two-Stage Hybrid)
    \item Implement Algorithm D1 (Multi-Objective Optimization)
    \item Conduct fairness audits
    \item Pilot with subset of enrollees
\end{itemize}

\textbf{Phase 3: Specialized Models}
\begin{itemize}
    \item Implement Algorithm E1 (Dynamic Regression)
    \item Deploy Algorithm F1 (Latent Class Mixture)
    \item Full system integration
    \item Policy compliance verification
\end{itemize}

\section{Conclusion}

The current iBudget algorithm exhibits significant limitations in prediction accuracy, temporal validity, and compliance with person-centered planning requirements mandated by House Bill 1103. The proposed collection of alternative algorithms addresses these deficiencies through:

\begin{enumerate}
    \item \textbf{Enhanced statistical robustness} via outlier-resistant methods
    \item \textbf{Person-centered integration} through multi-objective optimization
    \item \textbf{Temporal adaptability} using dynamic regression approaches  
    \item \textbf{Specialized population modeling} via mixture models
    \item \textbf{Fairness assurance} through constrained optimization
    \item \textbf{Transparency and explainability} via interpretable ML methods
\end{enumerate}

The mathematical formulations and Python implementations provided offer a comprehensive foundation for developing a next-generation iBudget allocation system that meets both statistical rigor and regulatory compliance requirements. The phased implementation approach ensures systematic validation and stakeholder engagement throughout the transition process.

Key success metrics for the new algorithms should include:
\begin{align}
R^2 &\geq 0.85 \text{ (vs. current 0.80)} \\
\text{Outlier Rate} &\leq 2\% \text{ (vs. current 9.4\%)} \\
\text{Fairness Score} &\geq 0.95 \\
\text{Person-Centered Compliance} &\geq 0.90
\end{align}

This comprehensive approach ensures Florida's iBudget system evolves to better serve individuals with developmental disabilities while maintaining fiscal responsibility and regulatory compliance.
