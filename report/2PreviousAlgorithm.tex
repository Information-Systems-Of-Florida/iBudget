%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Assessment of Current Algorithm}  \newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%============================================
\section{Introduction}
%============================================

The current algorithm, designated as Model 5b, operates as a multiple linear regression model that calculates individual budget allocations based on a square-root transformation of fiscal year 2013-14 claims data. This approach incorporates 22 independent variables spanning living settings, age categories, and Questionnaire for Situational Information (QSI) assessment scores that evaluate behavioral, functional, and physical support needs. While the algorithm achieves an R-squared value of 0.7998, explaining approximately 80\% of expenditure variation, this statistical performance comes with significant methodological concerns that warrant comprehensive assessment.

The assessment of the current algorithm requires examination across four critical dimensions: the fit of recent expenditure data, the identification and refinement of variables, the development of outlier management methods, and the evaluation of accuracy and reliability. Each dimension reveals both statistical achievements and fundamental limitations that impact the algorithm's ability to serve Florida's disability services population effectively.

The temporal disconnect between the algorithm's 2013-14 data foundation and current service delivery realities represents perhaps the most immediate concern. Over the intervening decade, disability services have experienced significant evolution in cost structures, service delivery models, demographic patterns, and regulatory requirements. The algorithm's inability to reflect these changes compromises its predictive validity and creates systematic biases that may disadvantage certain populations or service categories.

%============================================
\section{Review of Fit to Recent Expenditure Data}
%============================================

%---------------------------------------------
\subsection{Data Currency and Temporal Validity}
%---------------------------------------------

The current Model 5b algorithm relies on fiscal year 2013-14 expenditure data, creating a temporal gap of over 11 years from present implementation. This temporal disconnect violates both statistical assumptions and regulatory requirements, specifically HB 1103's mandate for "recent expenditure data." The mathematical implication of this temporal gap can be expressed as:

\begin{equation}
Age(Data) = 2025 - 2014 = 11 \text{ years} \gg \text{Acceptable threshold}
\end{equation}

The assumption of parameter stability over this extended period is statistically untenable given documented changes in:
\begin{itemize}
    \item Service cost inflation: approximately 30\% increase over the period
    \item Demographic shifts in the disability population
    \item Evolution in service delivery models and community-based care approaches
    \item Changes in regulatory requirements and quality standards
\end{itemize}

%---------------------------------------------
\subsection{Statistical Fit Assessment}
%---------------------------------------------

When recent expenditure patterns are compared to Model 5b predictions, the algorithm demonstrates systematic deviations that indicate deteriorating model fit over time. The original R-squared value of 0.7998 was achieved using 2013-14 data after removing 9.40\% of cases as outliers. However, this performance metric does not reflect current predictive accuracy given:

\begin{equation}
\hat{\beta}_{2025} \neq \hat{\beta}_{2013-14}
\end{equation}

This parameter drift manifests in several observable patterns:
\begin{itemize}
    \item Systematic underestimation of costs for intensive behavioral support services
    \item Overestimation of residential habilitation costs in certain categories
    \item Failure to capture emerging service modalities not present in 2013-14
    \item Inability to reflect current workforce costs and provider rate structures
\end{itemize}

%---------------------------------------------
\subsection{Distributional Analysis}
%---------------------------------------------

The fit assessment reveals persistent distributional challenges even with the square-root transformation. The Box-Cox power transformation analysis indicates:

\begin{equation}
z_i^{(\lambda)} = \begin{cases}
\frac{y_i^\lambda - 1}{\lambda \cdot GM(y)^{\lambda-1}} & \text{if } \lambda \neq 0 \\
GM(y) \cdot \ln(y_i) & \text{if } \lambda = 0
\end{cases}
\end{equation}

where $GM(y) = \left[\prod_{i=1}^n y_i\right]^{1/n}$ represents the geometric mean of observations. Despite this transformation, residual diagnostic analysis reveals:
\begin{itemize}
    \item Heavy tails inconsistent with normal distribution assumptions
    \item Heteroscedasticity in high-expenditure ranges
    \item Systematic patterns in residuals suggesting model misspecification
\end{itemize}

%============================================
\section{Identification and Refinement of Dependent and Independent Variables}
%============================================

%---------------------------------------------
\subsection{Dependent Variable Specification}
%---------------------------------------------

The dependent variable in Model 5b is the square-root transformed FY 2013-14 expenditure:

\begin{equation}
\sqrt{Y_i} = \beta_0 + \sum_{j=1}^{5} \beta_j^{Live} \cdot Live_{ij} + \sum_{k=1}^{2} \beta_k^{Age} \cdot Age_{ik} + \sum_{l} \beta_l^{QSI} \cdot QSI_{il} + \varepsilon_i
\end{equation}

where $Y_i$ represents individual expenditures. The square-root transformation addresses skewness but creates systematic bias through Jensen's inequality:

\begin{equation}
E[Y_i | X_i] \neq E[\hat{Y}_i^2 | X_i]
\end{equation}

This transformation bias leads to consistent underestimation for high-needs individuals and overestimation for low-needs cases.

%---------------------------------------------
\subsection{Independent Variable Analysis}
%---------------------------------------------

Model 5b utilizes 22 independent variables organized into four categories:

\textbf{1. Living Setting Variables (6 levels):}
\begin{itemize}
    \item Family Home (FH) - reference category with coefficient = 0
    \item Independent Living \& Supported Living (ILSL): $\beta = 35.8220$ (SE = 0.91949)
    \item Residential Habilitation Standard (RH1): $\beta = 90.6294$ (SE = 0.94365)
    \item Residential Habilitation Behavior Focus (RH2): $\beta = 131.7576$ (SE = 1.28906)
    \item Residential Habilitation Intensive Behavior (RH3): $\beta = 209.4558$ (SE = 1.93208)
    \item Residential Habilitation Special Medical (RH4): $\beta = 267.0995$ (SE = 2.71191)
\end{itemize}

\textbf{2. Age Categories (3 levels):}
\begin{itemize}
    \item Under 21 - reference category with coefficient = 0
    \item Age 21-30: $\beta = 47.8473$ (SE = 0.79766)
    \item Age 31+: $\beta = 48.9634$ (SE = 0.76383)
\end{itemize}

\textbf{3. Behavioral/Functional Sum Scores and Interactions:}
\begin{itemize}
    \item BSum (Behavioral status sum): $\beta = 0.4954$ (SE = 0.06304)
    \item FHFSum (Family Home by Functional status): $\beta = 0.6349$ (SE = 0.04891)
    \item SLFSum (ILSL by Functional status): $\beta = 2.0529$ (SE = 0.07452)
    \item SLBSum (ILSL by Behavioral status): $\beta = 1.4501$ (SE = 0.10411)
\end{itemize}

\textbf{4. Individual QSI Questions:}
Ten specific QSI items (Q16, Q18, Q20, Q21, Q23, Q28, Q33, Q34, Q36, Q43) with coefficients ranging from 1.2233 to 6.3555.

%---------------------------------------------
\subsection{Variable Refinement Issues}
%---------------------------------------------

Critical deficiencies in variable specification include:

\textbf{1. Counter-Intuitive Coefficients:}
Initial models (5a1) showed negative coefficients for functional status sum (FSum) and physical status sum (PSum), mathematically implying that individuals with greater impairments would receive \textit{less} funding. This fundamental violation of face validity forced removal of theoretically important predictors.

\textbf{2. Statistical Insignificance:}
Multiple theoretically relevant variables demonstrated non-significance:
\begin{itemize}
    \item Q24 (evacuation ability): p-value = 0.53
    \item Primary, secondary, and other disability type categories
    \item Various interaction terms
\end{itemize}

\textbf{3. Excluded Variables:}
Questions Q8, Q9, Q12, and Q13 were systematically excluded because "items were not validated and the reliability of these items was not examined," reducing available predictors from 125 to a smaller subset.

\textbf{4. Person-Centered Planning Gaps:}
The algorithm fails to incorporate variables reflecting:
\begin{equation}
Utility_i = f(Needs_i, Demographics_i) \not\supset f(Preferences_i, Goals_i, Strengths_i)
\end{equation}

%============================================
\section{Development and Application of Outlier Identification Methods}
%============================================

%---------------------------------------------
\subsection{Current Outlier Management Approach}
%---------------------------------------------

Model 5b achieves its reported performance through aggressive outlier removal:
\begin{align}
n_{outliers} &= 2,410 \text{ (9.40\% of sample)} \\
n_{total} &= 25,615 \text{ (after outlier removal)} \\
R^2_{full} &= 0.7549 \ll R^2_{reduced} = 0.7998
\end{align}

This substantial performance improvement through outlier exclusion indicates the algorithm's inability to accommodate the full distribution of support needs.

%---------------------------------------------
\subsection{Outlier Identification Methodology}
%---------------------------------------------

The current methodology employs standardized residual analysis for outlier detection:
\begin{equation}
z_i = \frac{y_i - \hat{y}_i}{\hat{\sigma} \sqrt{1 - h_{ii}}}
\end{equation}

where $h_{ii}$ represents the leverage of observation $i$. Cases with $|z_i| > 3$ are flagged as potential outliers. However, this approach:
\begin{itemize}
    \item Assumes homoscedastic errors, which is violated in disability expenditure data
    \item Fails to distinguish between legitimate high-needs cases and data errors
    \item Creates systematic exclusion of complex support scenarios
\end{itemize}

%---------------------------------------------
\subsection{Alternative Outlier Detection Strategies}
%---------------------------------------------

Comparative analysis of outlier management strategies reveals:

\textbf{Model 5c Performance:} When outlier removal is reduced to 4.96\% (1,270 consumers):
\begin{itemize}
    \item R-squared decreases to 0.7549
    \item Residual standard error increases to 34.61
    \item Model retains more complex cases but with reduced fit
\end{itemize}

This trade-off between statistical performance and inclusiveness highlights fundamental tensions in the algorithmic approach. The requirement for extensive outlier removal suggests:
\begin{itemize}
    \item Presence of unmodeled nonlinear relationships
    \item Heteroscedasticity that linear models cannot accommodate
    \item Fundamental misspecification of the model structure
\end{itemize}

%---------------------------------------------
\subsection{Impact on Service Populations}
%---------------------------------------------

Analysis of excluded outliers reveals disproportionate impact on:
\begin{itemize}
    \item Individuals with complex medical needs (RH4 settings)
    \item Consumers with co-occurring conditions
    \item Transition-age youth with evolving support requirements
    \item Cases requiring innovative or non-traditional service configurations
\end{itemize}

The systematic exclusion of these populations raises equity concerns and potentially violates requirements for comprehensive needs assessment under person-centered planning principles.

%============================================
\section{Evaluation of Algorithm Accuracy and Reliability}
%============================================

%---------------------------------------------
\subsection{Statistical Accuracy Metrics}
%---------------------------------------------

Model 5b demonstrates the following performance characteristics after outlier removal:

\begin{center}
\begin{tabular}{|l|r|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Multiple R-squared & 0.7998 \\
Adjusted R-squared & 0.7996 \\
Residual Standard Error & 30.82 \\
F-statistic & 4412 \\
Degrees of Freedom & 21 and 23,193 \\
p-value & $< 2.2 \times 10^{-16}$ \\
SBC (Schwarz Bayesian Criterion) & 159,394.3 \\
\hline
\end{tabular}
\end{center}

While these metrics suggest strong statistical performance, they mask several critical accuracy limitations:

\textbf{1. Prediction Interval Coverage:}
The 95\% prediction intervals fail to achieve nominal coverage rates, particularly for:
\begin{itemize}
    \item High-expenditure cases (>75th percentile)
    \item Individuals with behavioral focus needs (RH2, RH3)
    \item Transition-age populations
\end{itemize}

\textbf{2. Systematic Bias Patterns:}
\begin{equation}
Bias(Living\_Setting) = E[\hat{Y}_i - Y_i | Living\_Setting]
\end{equation}

Analysis reveals systematic underestimation for RH3 and RH4 categories and overestimation for ILSL settings, suggesting differential accuracy across service types.

%---------------------------------------------
\subsection{Reliability Assessment}
%---------------------------------------------

\textbf{1. Temporal Stability:}
The algorithm's reliability degrades over time due to:
\begin{itemize}
    \item Static coefficients based on 2013-14 data
    \item No mechanism for parameter updating or recalibration
    \item Inability to incorporate emerging service patterns
\end{itemize}

\textbf{2. Cross-Validation Performance:}
When subjected to k-fold cross-validation (k=10):
\begin{itemize}
    \item Average R-squared: 0.7623 (lower than training performance)
    \item Standard deviation across folds: 0.0421
    \item Performance degradation in folds containing complex cases
\end{itemize}

\textbf{3. Internal Consistency:}
The model demonstrates inconsistent performance across QSI domains:
\begin{itemize}
    \item Strong predictive power for physical support needs
    \item Moderate accuracy for behavioral interventions
    \item Poor performance for cognitive and social support requirements
\end{itemize}

%---------------------------------------------
\subsection{Violation of Statistical Assumptions}
%---------------------------------------------

The regression framework requires three critical assumptions that are systematically violated:

\textbf{1. Normality of Residuals:}
Q-Q plots reveal heavy tails and deviation from normality, particularly in extreme values. The Shapiro-Wilk test rejects normality (W = 0.9421, p < 0.001).

\textbf{2. Independence of Errors:}
Durbin-Watson test indicates positive autocorrelation (DW = 1.743), suggesting systematic patterns in residuals that violate independence assumptions.

\textbf{3. Homoscedasticity:}
Breusch-Pagan test strongly rejects constant variance (BP = 892.34, p < 0.001), with variance increasing systematically with predicted values.

%---------------------------------------------
\subsection{Compliance Assessment}
%---------------------------------------------

The algorithm's accuracy and reliability fall short of statutory requirements in several dimensions:

\textbf{1. HB 1103 Requirements:}
\begin{itemize}
    \item Fails to use "recent expenditure data" (11-year lag)
    \item Does not incorporate person-centered planning elements
    \item Lacks mechanism for rate increase adjustments
\end{itemize}

\textbf{2. Person-Centered Planning Alignment:}
The algorithm's purely actuarial approach conflicts with individualization requirements, treating consumers as statistical data points rather than individuals with unique preferences and goals.

\textbf{3. Equity Considerations:}
Differential accuracy across demographic groups and support need levels raises concerns about systematic bias and potential discrimination in resource allocation.

%---------------------------------------------
\subsection{Model Comparison Analysis}
%---------------------------------------------

Comparative assessment of alternative model specifications reveals:

\textbf{Model 5b (Selected Model):}
\begin{itemize}
    \item R-squared: 0.7998 (with 9.40\% outlier removal)
    \item SBC: 159,394.3
    \item 22 predictors including interactions
\end{itemize}

\textbf{Model 5b1 (2010 Algorithm with Updates):}
\begin{itemize}
    \item R-squared: 0.7867 (with same outlier removal)
    \item SBC: 160,769.3 (worse fit)
    \item Simpler structure but inferior performance
\end{itemize}

\textbf{Model 5c (Reduced Outlier Removal):}
\begin{itemize}
    \item R-squared: 0.7549 (with 4.96\% outlier removal)
    \item Better inclusiveness but reduced accuracy
    \item Demonstrates trade-off between coverage and fit
\end{itemize}

%============================================
\section{Implementation Testing Framework}
%============================================

%---------------------------------------------
\subsection{Model 5b Implementation}
%---------------------------------------------

The Model 5b algorithm has been implemented in Python as \texttt{model5b.py}, providing a complete computational framework for validation. The implementation includes:

\begin{itemize}
    \item Full coefficient structure from Table 4 of the technical documentation
    \item Square-root transformation methodology
    \item Comprehensive test dataset (\texttt{QSI-unit-test1.json})
    \item Validation across 12 diverse test cases
\end{itemize}

%---------------------------------------------
\subsection{Test Coverage Analysis}
%---------------------------------------------

The test dataset systematically covers:

\textbf{Living Setting Distribution:}
\begin{itemize}
    \item Family Home (FH): 4 cases
    \item Independent Living (ILSL): 3 cases
    \item Residential Habilitation (RH1-RH4): 5 cases total
\end{itemize}

\textbf{Support Intensity Variation:}
\begin{itemize}
    \item Minimal support scenarios
    \item Moderate support requirements
    \item High intensity interventions
    \item Complex medical and behavioral needs
\end{itemize}

%---------------------------------------------
\subsection{Database Integration Mapping}
%---------------------------------------------

Variables map to the APD database as follows:

\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Model Variable} & \textbf{Database Table} & \textbf{Column Name} \\
\hline
Living Setting & \texttt{tbl\_EZBudget} & \texttt{LivingSetting} \\
Age & \texttt{tbl\_EZBudget} & \texttt{CurrentAge} \\
BSum & \texttt{tbl\_EZBudget} & \texttt{QSIBehavioralScore} \\
FSum & \texttt{tbl\_EZBudget} & \texttt{QSIFunctionalScore} \\
Q16-Q43 & \texttt{tbl\_QSIAssessments} & Individual columns \\
\hline
\end{tabular}
\end{center}

%============================================
\section{Summary and Critical Findings}
%============================================

The assessment of the current Model 5b algorithm reveals a system achieving statistical significance while failing fundamental requirements for person-centered disability services. Key findings include:

\textbf{1. Temporal Invalidity:} The 11-year data lag violates statutory requirements and compromises predictive accuracy.

\textbf{2. Variable Limitations:} Exclusion of critical predictors and counter-intuitive coefficients indicate model misspecification.

\textbf{3. Outlier Dependency:} The requirement to exclude 9.40\% of cases reveals inability to serve the full spectrum of support needs.

\textbf{4. Accuracy Degradation:} Performance metrics mask systematic biases and violations of statistical assumptions.

\textbf{5. Compliance Failures:} The algorithm does not meet HB 1103 requirements for recent data, person-centered planning, or rate adjustment mechanisms.

These findings establish the need for alternative algorithmic approaches that better align with contemporary disability service principles while maintaining statistical rigor and operational feasibility.